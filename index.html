<html>
<head>
<title>The Commonplace Script</title>

<style>
body {
  font-family: Arial, "Helvetica Neue", Helvetica, sans-serif;
  color: #333;
  margin: 0;
  background-color: #EDE7F6;

}
h1 {
  font-family: Arial, "Helvetica Neue", Helvetica, sans-serif;
  margin-top: 0;
  margin-bottom: 0;
  color: #ffffff;
  padding: 20px;
  background-color: #673AB7;
}
#argmax {
  background-color: #DFD;
}
#ppl {
  color: #090;
  font-size: 20px;
}
#epoch {
  color: #900;
  font-size: 20px;
}
.header {
  width: 100%;

  margin-left: auto;
  margin-top: 0;
  margin-right: auto;
  padding:0;
}
#wrap {
  width: 100%;
  max-width: 800px;
  background-color: #ffffff;
  padding: 10;

  margin-right: auto;
  margin-left: auto;
  margin-bottom: 0;
}
.apred {
  height: 600px;
  padding: 2px;
  margin-top: 5px;
  margin-bottom: 5px;
  margin-left: auto;
  margin-right: auto;
  overflow-y: auto;
  overflow y: hidden;
  font-size: 12px;

  background-color: #ffffff;
}
#prepro_status {
  background-color: #FFD;
  padding: 5px;
}
#status {
  padding: 2px;
  margin-top: 5px;
}
#controls {
  margin: 5px;
}
.theslider {
  width:100%;
  display: inline-block;
}
.slider_value {
  width: 9%;
  display: inline-block;
}
.slider_header {
  padding-bottom: 5px
}
.abutton {
  background-color: #4DD0E1;
  border-radius: 20px;
  width: 120px;
  height: 30px;
  text-align: center;
  margin: 10px 10px 10px 10px;
}
.hh {
  color: #ffffff;
  background-color: #9575CD;
  text-align: center;
  padding: 5px;
  margin-top: 5px;
  border-bottom: 1px solid #999;
  margin-bottom: 2px;
}
#pplgraph {
  float: right;
}
#intro {
  color: #ffffff;
  text-align: justify;
  padding: 10px;
  width: 100%;
  max-width: 800px;
  margin-left: auto;
  margin-right: auto;
  background-color: #9575CD;

}
.aboutButton {
  background-color: #FFF9C4;
  border: 1px solid black;
  padding: 0;
  border-radius: 20px;
}
</style>
<link href="external/jquery-ui.min.css" rel="stylesheet">

<script src="external/jquery-1.8.3.min.js"></script>
<script src="external/jquery-ui.min.js"></script>

<script src="src/recurrent.js"></script>
<script src="src/vis.js"></script>
<script type="text/javascript">

// prediction params
var sample_softmax_temperature = 1.0; // how peaky model predictions should be
var max_chars_gen = 100; // max length of generated sentences

// various global var inits
var epoch_size = -1;
var input_size = -1;
var output_size = -1;
var letterToIndex = {};
var indexToLetter = {};
var vocab = [];
var data_sents = [];
var solver = new R.Solver(); // should be class because it needs memory for step caches
var pplGraph = new Rvis.Graph();
var newSentence = [];


var model = {};

var initVocab = function(sents, count_threshold) {
  // go over all characters and keep track of all unique ones seen
  var txt = sents.join(''); // concat all

  // count up all characters
  var d = {};
  for(var i=0,n=txt.length;i<n;i++) {
    var txti = txt[i];
    if(txti in d) { d[txti] += 1; }
    else { d[txti] = 1; }
  }

  // filter by count threshold and create pointers
  letterToIndex = {};
  indexToLetter = {};
  vocab = [];
  // NOTE: start at one because we will have START and END tokens!
  // that is, START token will be index 0 in model letter vectors
  // and END token will be index 0 in the next character softmax
  var q = 1;
  for(ch in d) {
    if(d.hasOwnProperty(ch)) {
      if(d[ch] >= count_threshold) {
        // add character to vocab
        letterToIndex[ch] = q;
        indexToLetter[q] = ch;
        vocab.push(ch);
        q++;
      }
    }
  }

  // globals written: indexToLetter, letterToIndex, vocab (list), and:
  input_size = vocab.length + 1;
  output_size = vocab.length + 1;
  epoch_size = sents.length;
  $("#prepro_status").text('found ' + vocab.length + ' distinct characters: ' + vocab.join(''));
}

var utilAddToModel = function(modelto, modelfrom) {
  for(var k in modelfrom) {
    if(modelfrom.hasOwnProperty(k)) {
      // copy over the pointer but change the key to use the append
      modelto[k] = modelfrom[k];
    }
  }
}

var initModel = function() {
  // letter embedding vectors
  var model = {};
  model['Wil'] = new R.RandMat(input_size, letter_size , 0, 0.08);

  if(generator === 'rnn') {
    var rnn = R.initRNN(letter_size, hidden_sizes, output_size);
    utilAddToModel(model, rnn);
  } else {
    var lstm = R.initLSTM(letter_size, hidden_sizes, output_size);
    utilAddToModel(model, lstm);
  }

  return model;
}
//section that controls inital learning slider value
var reinit_learning_rate_slider = function() {
  // init learning rate slider for controlling the decay
  // note that learning_rate is a global variable
  $("#lr_slider").slider({
    min: Math.log10(0.01) - 3.0,
    max: Math.log10(0.01) + 0.05,
    step: 0.05,
    value: Math.log10(learning_rate),
    slide: function( event, ui ) {
      learning_rate = Math.pow(10, ui.value);
      $("#lr_text").text(learning_rate.toFixed(5));
    }
  });
  $("#lr_text").text(learning_rate.toFixed(5));
}

var reinit = function() {
  // note: reinit writes global vars

  // eval options to set some globals
  eval($("#newnet").val());

  reinit_learning_rate_slider();

  solver = new R.Solver(); // reinit solver
  pplGraph = new Rvis.Graph();

  ppl_list = [];
  tick_iter = 0;

  // process the input, filter out blanks
  //this is where the input text is first analysed
  var data_sents_raw = $('#ti').val().split('\n');
  data_sents = [];
  for(var i=0;i<data_sents_raw.length;i++) {
    var sent = data_sents_raw[i].trim();
    if(sent.length > 0) {
      data_sents.push(sent);
    }
  }

  initVocab(data_sents, 1); // takes count threshold for characters
  model = initModel();
}

var saveModel = function() {
  var out = {};
  out['hidden_sizes'] = hidden_sizes;
  out['generator'] = generator;
  out['letter_size'] = letter_size;
  var model_out = {};
  for(var k in model) {
    if(model.hasOwnProperty(k)) {
      model_out[k] = model[k].toJSON();
    }
  }
  out['model'] = model_out;
  var solver_out = {};
  solver_out['decay_rate'] = solver.decay_rate;
  solver_out['smooth_eps'] = solver.smooth_eps;
  step_cache_out = {};
  for(var k in solver.step_cache) {
    if(solver.step_cache.hasOwnProperty(k)) {
      step_cache_out[k] = solver.step_cache[k].toJSON();
    }
  }
  solver_out['step_cache'] = step_cache_out;
  out['solver'] = solver_out;
  out['letterToIndex'] = letterToIndex;
  out['indexToLetter'] = indexToLetter;
  out['vocab'] = vocab;
  $("#tio").val(JSON.stringify(out));
}

var loadModel = function(j) {
  hidden_sizes = j.hidden_sizes;
  generator = j.generator;
  letter_size = j.letter_size;
  model = {};
  for(var k in j.model) {
    if(j.model.hasOwnProperty(k)) {
      var matjson = j.model[k];
      model[k] = new R.Mat(1,1);
      model[k].fromJSON(matjson);
    }
  }
  solver = new R.Solver(); // have to reinit the solver since model changed
  solver.decay_rate = j.solver.decay_rate;
  solver.smooth_eps = j.solver.smooth_eps;
  solver.step_cache = {};
  for(var k in j.solver.step_cache){
      if(j.solver.step_cache.hasOwnProperty(k)){
          var matjson = j.solver.step_cache[k];
          solver.step_cache[k] = new R.Mat(1,1);
          solver.step_cache[k].fromJSON(matjson);
      }
  }
  letterToIndex = j['letterToIndex'];
  indexToLetter = j['indexToLetter'];
  vocab = j['vocab'];

  // reinit these
  ppl_list = [];
  tick_iter = 0;
}

var forwardIndex = function(G, model, ix, prev) {
  var x = G.rowPluck(model['Wil'], ix);
  // forward prop the sequence learner
  if(generator === 'rnn') {
    var out_struct = R.forwardRNN(G, model, hidden_sizes, x, prev);
  } else {
    var out_struct = R.forwardLSTM(G, model, hidden_sizes, x, prev);
  }
  return out_struct;
}

var predictSentence = function(model, samplei, temperature) {
  if(typeof samplei === 'undefined') { samplei = false; }
  if(typeof temperature === 'undefined') { temperature = 1.0; }

  var G = new R.Graph(false);
  var s = '';
  var prev = {};
  while(true) {

    // RNN tick
    var ix = s.length === 0 ? 0 : letterToIndex[s[s.length-1]];
    var lh = forwardIndex(G, model, ix, prev);
    prev = lh;

    // sample predicted letter
    logprobs = lh.o;
    if(temperature !== 1.0 && samplei) {
      // scale log probabilities by temperature and renormalize
      // if temperature is high, logprobs will go towards zero
      // and the softmax outputs will be more diffuse. if temperature is
      // very low, the softmax outputs will be more peaky
      for(var q=0,nq=logprobs.w.length;q<nq;q++) {
        logprobs.w[q] /= temperature;
      }
    }

    probs = R.softmax(logprobs);
    if(samplei) {
      var ix = R.samplei(probs.w);
    } else {
      var ix = R.maxi(probs.w);
    }
//this is where the character count is implemented
    if(ix === 0) break; // END token predicted, break out
    if(s.length > max_chars_gen) { break; } // something is wrong

    var letter = indexToLetter[ix];
    s += letter;
  }
  return s;
}

var costfun = function(model, sent) {
  // takes a model and a sentence and
  // calculates the loss. Also returns the Graph
  // object which can be used to do backprop
  var n = sent.length;
  var G = new R.Graph();
  var log2ppl = 0.0;
  var cost = 0.0;
  var prev = {};
  for(var i=-1;i<n;i++) {
    // start and end tokens are zeros
    var ix_source = i === -1 ? 0 : letterToIndex[sent[i]]; // first step: start with START token
    var ix_target = i === n-1 ? 0 : letterToIndex[sent[i+1]]; // last step: end with END token

    lh = forwardIndex(G, model, ix_source, prev);
    prev = lh;

    // set gradients into logprobabilities
    logprobs = lh.o; // interpret output as logprobs
    probs = R.softmax(logprobs); // compute the softmax probabilities

    log2ppl += -Math.log2(probs.w[ix_target]); // accumulate base 2 log prob and do smoothing
    cost += -Math.log(probs.w[ix_target]);

    // write gradients into log probabilities
    logprobs.dw = probs.w;
    logprobs.dw[ix_target] -= 1
  }
  var ppl = Math.pow(2, log2ppl / (n - 1));
  return {'G':G, 'ppl':ppl, 'cost':cost};
}

function median(values) {
  values.sort( function(a,b) {return a - b;} );
  var half = Math.floor(values.length/2);
  if(values.length % 2) return values[half];
  else return (values[half-1] + values[half]) / 2.0;
}

var ppl_list = [];
var tick_iter = 0;
var tick = function() {

  // sample sentence fromd data
  var sentix = R.randi(0,data_sents.length);
  var sent = data_sents[sentix];

  var t0 = +new Date();  // log start timestamp

  // evaluate cost function on a sentence
  var cost_struct = costfun(model, sent);

  // use built up graph to compute backprop (set .dw fields in mats)
  cost_struct.G.backward();
  // perform param update
  var solver_stats = solver.step(model, learning_rate, regc, clipval);
  //$("#gradclip").text('grad clipped ratio: ' + solver_stats.ratio_clipped)

  var t1 = +new Date();
  var tick_time = t1 - t0;

  ppl_list.push(cost_struct.ppl); // keep track of perplexity

  // evaluate now and then

  /******     this is the section that creates the rules for sentences that are generated    ***********/

  tick_iter += 1;
  //recreation rate

  if(tick_iter % 20 === 0) {
    // draw samples
    $('#samples').html('');
      //this is the actual sentence
      var pred = predictSentence(model, true, sample_softmax_temperature);
      //this is the creator for the class that calls the sentence

      //this adds the most recent class stats to the "samples" class in order for it to be displayed
      //I need the sentence array to take the current version of pred(the predicted sentence)
      newSentence.push(pred);

//I need the array to be displayed. And as more sentences are generated I need them to be added to the displayed string.
//I want all the sentences to be a part of one block of text.

      var paragraph = newSentence.join('. ');
      //counts the words in the paragraph by analysing the number of spaces
      var wordCount = (paragraph.match(/ /g)).length;
      //reinititiates paragraph each check.
      var pred_div = '<div class="apred">' + ' ' + paragraph + "." + '</div>'
      $('#samples').append(pred_div);
      //if word count is greater than 1000, remove the first sentence.
      if (wordCount > 1000) {
        newSentence.splice(0, 1);
      }
  }

  /*******************************************************************************************************/

  if(tick_iter % 10 === 0) {
    // draw argmax prediction
    $('#argmax').html('');
    var pred = predictSentence(model, false);
    var pred_div = '<div class="apred">'+pred+'</div>'
    $('#argmax').append(pred_div);

    // keep track of perplexity
    $('#epoch').text('epoch: ' + (tick_iter/epoch_size).toFixed(2));
    $('#ppl').text('perplexity: ' + cost_struct.ppl.toFixed(2));
    $('#ticktime').text('forw/bwd time per example: ' + tick_time.toFixed(1) + 'ms');

    if(tick_iter % 100 === 0) {
      var median_ppl = median(ppl_list);
      ppl_list = [];
      pplGraph.add(tick_iter, median_ppl);
      pplGraph.drawSelf(document.getElementById("pplgraph"));
    }
  }
}


var gradCheck = function() {
  var model = initModel();
  var sent = '^test sentence$';
  var cost_struct = costfun(model, sent);
  cost_struct.G.backward();
  var eps = 0.000001;

  for(var k in model) {
    if(model.hasOwnProperty(k)) {
      var m = model[k]; // mat ref
      for(var i=0,n=m.w.length;i<n;i++) {

        oldval = m.w[i];
        m.w[i] = oldval + eps;
        var c0 = costfun(model, sent);
        m.w[i] = oldval - eps;
        var c1 = costfun(model, sent);
        m.w[i] = oldval;

        var gnum = (c0.cost - c1.cost)/(2 * eps);
        var ganal = m.dw[i];
        var relerr = (gnum - ganal)/(Math.abs(gnum) + Math.abs(ganal));
        if(relerr > 1e-1) {
          console.log(k + ': numeric: ' + gnum + ', analytic: ' + ganal + ', err: ' + relerr);
        }
      }
    }
  }
}

var iid = null;
$(function() {

  // attach button handlers
  $('#learn').click(function(){
    reinit();
    if(iid !== null) { clearInterval(iid); }
    iid = setInterval(tick, 0);
  });
  $('#stop').click(function(){
    if(iid !== null) { clearInterval(iid); }
    iid = null;
  });
  $("#resume").click(function(){
    if(iid === null) {
      iid = setInterval(tick, 0);
    }
  });


  $("#savemodel").click(saveModel);
  $("#loadmodel").click(function(){
    var j = JSON.parse($("#tio").val());
    loadModel(j);
  });

  $("#loadpretrained").click(function(){
    $.getJSON("lstm_100_model.json", function(data) {
      pplGraph = new Rvis.Graph();
      learning_rate = 0.01;
      reinit_learning_rate_slider();
      loadModel(data);
    });
  });

  $("#learn").click(); // simulate click on startup
  //$('#gradcheck').click(gradCheck);

  $("#temperature_slider").slider({
    min: -1,
    max: 1.05,
    step: 0.05,
    value: 0,
    slide: function( event, ui ) {
      sample_softmax_temperature = Math.pow(10, ui.value);
      $("#temperature_text").text( sample_softmax_temperature.toFixed(2) );
    }
  });
});

</script>


</head>

<body>
  <div class="header">
    <h1 style=" text-align: center;">The Commonplace Script</h1>
    <div id="intro">
      Through studying my readings about AI (Artificial intelligence - Kevin Warwick), Web Development(100 ideas that changed the web - Jim Boulton), art(Creativity and Art - Margeret A. Boden), Neuropsychology(Neuropsychology - David Andrews) and the future(Delouse and Futurism - Helen Palmer). The connections that I found were most profound were actually the ideas surrounding connections. Ironic, yes - but logical nonetheless.<br>
Through my readings of AI it is reinforced how AI are just smart systems that put weight on these connections in order to create meaningful outcomes. 100 ideas gives brief snippets of how connections via the internet have created real world change in perceptions and actions. Creativity and Art also surprised me in how the author mentions how machines can now be creative. Neuropsychology surprised me in how it was much less philosophical than I assumed it would be.  It instead went into great depths describing how various changes in perception change the way we think and make mental connections between things in the world.<br>


A quote from deleuzee and futurism:<br>
Art, it is said, is not a mirror, but a hammer: it does not reflect, it shapes. But at present even the handling of a hammer is taught with the help of a mirror, a sensitive film records that all the movements.<br>
- (leon Trotsky, literature and Revolution (1924),)<br>
<br>
I was inspired by this to take this new perception of connections and make something out of it that I previously couldn’t have conceived making. I took a Recurrent neural network (A deep learning algorithm) and manipulated it so when I parsed into it excerpts from these various texts  it would generate various “hybrid texts” based on the nuances of the content. I thought this method of manufacturing new connections was interesting and worth experimenting.<br>
It is in this that I create a self completing cycle in which I use my inspirations to generate something that may create new, novel connections in order to further fuel my inspirations. In essence expanding my creative ability and in turn becoming an extension of my creative will. The algorithm becomes not only my creation, but a part of my method of creating.
    </div>
  </div>
<div id="wrap">

  <div>
    <!-- this is where sample text will be written. -->
    <div id="samples"></div>

    <button id="learn" class="abutton">learn/restart</button>
    <button id="resume" class="abutton">resume</button>
    <button id="stop" class="abutton">pause</button>

    <div class="hh"> Insert text(s) here for analysis:</div>

<div>
    <textarea style="width:100%; height:100px; resize: none;" id="ti" >
      The three roads to surprise are the three forms of creativity: combinational, exploratory, and transformational. In previous writings, I’ve illustrated these by examples drawn from many different specialist domains, and from everyday life too (Boden 2004). Here, I relate them to art (as understood in the post-medieval Western tradition), and especially to the visual arts. Besides many references to traditional fine art, I also discuss some less orthodox approaches—namely, conceptual art and several types of computer art. Craftworks of various kinds are also considered, in the context of a new account of the distinction between art and craft. A brief statement of my threefold theory of creativity, which underlies this collection as a whole, is given in Chapter 2 (‘Creativity in a Nutshell’). Creativity in general is the generation of novel, surprising, and valuable ideas. ‘‘Ideas’’, here, is a catch-all term covering not only concepts and theories but also (for example) music and literature, and artefacts such as architecture, sculpture, and paintings. The three types of creativity, which elicit differing forms of surprise, are defined by the different kinds of psychological process that generate the new structures. As it happens, those processes have been greatly clarified by computer models of creativity. But that fact is not a core theme of this collection. If and when computers are mentioned here, it is in the context of computer art, not computer modelling. Computer modelling is a form of science, and most computer artists never engage in it. Like their fellow artists working in other genres, they have no particular interest in detailing the processes that may go on in human minds. (The leading exception is Harold Cohen, who in the late 1960s—when already a highly acclaimed abstract painter—embarked on his AARON suite of programs in order to throw light on his own creativity: Cohen 1981, 1995, 2002.) So the remarks in Chapter 2 that note the scientific value of computer models of creativity are not followed up in the other chapters (but see Boden 2004: chs. 5–8 and 12).2 Introduction Thefirstroadtosurprisethat’sidentifiedinChapter2is combinational creativity: the generation of unfamiliar combinations of familiar ideas. Most discussions of creativity, even in the specialist psychological literature (e.g. Sternberg 1988, 1999), consider only this type. (Of the roughly sixty definitions of creativity that had been offered by experts twenty years ago, almost all boiled down to this: Taylor 1988.) The combinational way of generating surprise is indeed important. It underlies most spontaneous jokes and wordplay, and is the key source of poetic/literaryimageryandvisualcollage—and(asarguedinChapter5) of conceptual art, too. But my account allows also for two other sorts of creativity. As explained in Chapter 2, these involve the exploration and transformation of familiar conceptual spaces—such as artistic styles. A style is a (culturally favoured) space of structural possibilities: not a painting, but away of painting. Or away of sculpting, or of composing fugues ... and so on. It’s partly because of these thinking styles that creativity has an ambiguous relationship with freedom. On the one hand, it’s commonly thought of as being the very opposite of disciplined, or rule-governed, behaviour. Creative ideas are surprising because they are unpredictable (and that is so for several reasons—Boden 2004: ch. 9). Some are so surprising that they strike us as outrageous (think of the unfamiliar combinations within the literary conceits in Finnegan’s Wake ). Indeed, some are deliberately intended to be outrageous (conceptual art, again). And transformational creativity, by definition, amends/ignores some normally respected constraints. So there’s a tempting launchpad, here, for neo-Romantic stories of the divine spark of creative freedom. On the other hand, all three types of creativity exploit stylistic and/or conceptual constraints. In exploratory creativity it’s especially clear that ‘‘artistic discipline’’ is not a contradiction in terms. But even the transformational variety preserves much of the preceding style. And even the most surprising visual juxtapositions (surrealism, perhaps), and the most challenging poetic imagery, have a connecting thread of intelligibility. (This is lacking, for instance, in the undisciplined outpourings of a schizophrenic’s ‘word-salad’—which, despite being unpredictable and occasionally suggestive to eavesdroppers, is not in itself an exercise of creative thinking.) That intelligibility is grounded in the rich network of conceptual structures in an adult’s mind (Boden 2004: chs. 5–6)—which structures are recognized by combinational creativity, not ignored by it.Introduction 3 These remarks imply that creativity also has an ambiguous position with respect to education, and in particular to autodidacts. For the ‘‘one hand’’ cited above suggests that a lack of conventional education need be no barrier to creativity—indeed, it’s commonly held that education may actually inhibit it. But the ‘‘other hand’’ stresses the importance of stylistic constraints that may require many years, and the help of dutiful tutors, to learn. So perhaps autodidacts, contrary to common belief, are actually at a disadvantage when it comes to creative thinking? In Chapter 3 (‘Are Autodidacts Creative?’), I outline the complex pattern of relationships between original thinking and self-education. As well as saying a little more about the three types of creativity, I distinguish three types of autodidact. The 3 × 3 matrix implied by these distinctions defines a variety of interrelationships between creativity and autodidacticism, sometimes mutually supportive and sometimes not. Most of those interrelationships apply irrespective of the domain concerned. In other words, art and science here are in much the same boat. Indeed, the threefold account of creativity sketched in Chapters 2 and 3 applies to both, and some scientific examples are mentioned there. The next eight chapters, however, focus on art. In ‘Crafts, Perception, and the Possibilities of the Body’ (Chapter 4), I compare creativity in the fine arts with craftsmanship. I also take up the old problem of distinguishing ‘‘art’’ from ‘‘craft’’. In one sense, I avoid that problem, for I don’t offer mutually exclusive definitions of these terms. Nor are satisfactory definitions available in the literature: quite apart from the hugely controversial question ‘‘What is art?’’, one historian has identified many competing interpretations of ‘‘craft’’, none of which is entirely apt (Harrod 1999: 10). Instead of offering definitions, I refer to many specific examples that are normally labelled as one or the other, and ask what are the differences between the two classes. My answer distinguishes the practices of art and craft, but also explains why they aren’t always clearly separable. That is, the difficulty of definition here goes beyond the fact that all everyday concepts are fuzzy, allowing for borderline cases and anomalies. There is a specific (psychological) reason why it is impossible to assign every relevant artefact to only one of these categories. The crafts are grounded in biologically evolved human tendencies to respond to certain things in particular ways. The psychologist’s jargon, here, is ‘‘affordances’’ (Gibson 1966). A pot or a textile, a chair or a sword, a box or a jewel, afford diverse opportunities for4 Introduction (fitness-related) action—which opportunities are readily, ‘naturally’, perceptible by Homo sapiens . The perception excites a disposition to act in a certain way: in general, to a pproach or to avoid the environmental feature concerned—so affordances embody basic values . (The play of affordances here is more complex than one might think: besides their more obvious functionalities, highly skilled craftworks—including the beautifully symmetrical, and unused, hand axes fashioned 1,400,000 years ago—are counters in the game of sexual selection, signalling their makers’ physical strength, muscular control, perceptual acuity, power of concentration, and endurance: Miller 2000.) In the case of craftworks, then, the value-criterion of creativity is grounded in our evolutionary biology. That’s why the aesthetics of craft are more stable, and its appreciation more cross-cultural, than the aesthetics of fine art. It’s sometimes said that a pure craftsman, untainted by ‘art-envy’ (see below), isn’t creative at all—merely skilled. I wouldn’t go that far. To the contrary, I’d say that craftsmen rely on exploratory creativity. But this is of a relatively unadventurous kind. Even an internationally famous master potter (for instance) may be aiming to produce yet another—albeit more perfect—example of something located in a part of the possibility space that has been visited many times before. The result can be an artefact that amazes us, in its (affordance-based) power to engage our attention/valuation. But if gaining our attention and positive valuation is part of the point of the exercise, producing amazement (or anyway, amazement-at-novelty) is not. In other words, the crafts downplay the role of surprise in creative work. Even the best examples typically display only minor novelty, and our wonder is elicited less by what is done than by its being done supremely well. The crafts aren’t dependent on highly imaginative combinational creativity, nor driven by increasingly adventurous exploratory creativity, nor sporadically progressed by transformational creativity—as fine art is. That’s not to say, however, that craftwork never involves journeying on these three roads to surprise. It’s true that the key mental capacities that underlie the generation (and appreciation) of craftwork differ from those which underlie fine art. The former relies on basic affordances, whereas the latter relies on the high-level psychological processes involved in learning, retaining, exploring, challenging, and (sometimes) transforming culturally specific concepts and/or artistic styles. But both types of mental process can occur within someone’sIntroduction 5 mind simultaneously, with respect to different properties of a single artefact. This psychological fact makes it possible for a potter, jeweller, or tapestry maker to exploit knowledge of specific fine-art styles in their work (various examples are given in Chapter 4). Indeed, it makes it possible for them to do this in order to raise their social status in a culture that values fine art over ‘mere’ crafts—hence my reference, above, to art-envy. Similarly, a professional craftsman irritated by unsympathetic cultural values ma y deliberately, and atypically, aim for surprise—byfollowingoneormoreofthethreeroadsI’vedistinguished. This explains why there can never be a definition of crafts that can unambiguously distinguish every individual craftwork from a work of art. In saying that craftworks don’t involve adventurous creativity, I’ve assumed that the craftworker is using already accepted techniques. But it is possible, of course, for someone to create (by combination, exploration, or transformation) a new way of firing pots, say, or of working metals. An intriguing recent example of the creative (combinational) use of novel techniques in craftwork is ‘digital jewellery’. Here, rings and bracelets are not only attractive physical adornments but also digital devices. Considered as items of jewellery, they afford [ sic ] the social communications for which jewellery has evolved (see Chapter 4). But they can do more, for impersonal digital techniques can be put to highly personal uses. For instance, digital jewellery may be connected with some remote location of personal significance to the wearer, such as their birthplace—where their family may still reside (Wallace et al. 2007). Instead of a Victorian locket containing a lover’s likeness, or a mourning brooch woven from a dead spouse’s hair, these baubles may display images/sounds drawn from the wearer’s own past, or from their far-flung relatives’ situation at this very moment . The crafts, then, typically underplay surprise—and are often dismissed as being uncreative, accordingly. But if surprise is a key criterion of creativity, the 1970s movement known as conceptual art shouldn’t suffer the same fate. On the contrary, it should be seen as highly creative. For to say that conceptual art is surprising is an understatement. It is shocking, bizarre, outrageous, challenging ... so much so, that it’s often said not to be art at all. In Chapter 5 (‘Creativity and Conceptual Art’), I ask just which sort of creativity it involves. Which of the three roads leads to these artistic astonishments?6 Introduction Prima facie, conceptual art may seem to be a case of transformational creativity. For its artworks are very different from traditional ones. Moreover, the conceptual artists were undoubtedly trying to effect a radical change in the public’s ideas and expectations about ‘‘art’’. However, not every radical change counts as a ‘‘transformation’’, in the (stylistic) sense that I define this. Looked at more closely, conceptual art is an example—or rather, a set of highly various examples (many described in Chapter 5)—of combinational creativity. Each of the individual artworks generated by this movement involves some unfamiliar, often highly challenging, juxtaposition of ideas. And ‘‘ideas’’ should be interpreted literally, here. For a conceptual artist, as opposed to an orthodox fine artist, the physical artefact is not the main point. Indeed, there may be no physical artefact, merely (for instance) a verbal injunction to imagine one. Even if there is, the artist may have ensured that it remains utterly invisible to the ‘audience’—by being buried, for example. The key aim, then, is not to generate intrinsically beautiful objects, nor disturbing ones either. Admittedly, Eduardo Kac outraged people by producing a genetically engineered albino rabbit that turned a f luorescent green in ultraviolet light. But even this was as much an idea as a thing: the notorious green image that sped around the world via the mass media was not an actual photograph, but a Photoshopgenerated design; and the rabbit was never publicly exhibited, because fears about mad-cow disease prevented agricultural movements around the laboratory where it was born. Nor do conceptual artists aim to display hard-won painterly or sculptural skills (so they might well be autodidacts: see Chapter 3). Rather, they aim to raise a host of questions in the minds of the audience. Many of these concern the nature of ‘‘art’’ itself—and its twentieth-century social context, the art market. Many of the conceptual artists were challenging the popular view of art wherein art is a highly personal matter: not merely effected by a person (not by a machine), but by some particular, unique, human individual. This view has its roots in the humanism of the Renaissance, but was strengthened by early nineteenth-centuryRomanticism. Coincidentally, the historical circumstances of the mid-nineteenth century led to a need (on the part of collectors and curators) for better ways of attributing old paintings or sculptures to one artist rather than another. And this, in turn, led pioneering art connoisseurs to identify the characteristic marks, or personal signatures, of different artists.Introduction 7 Chapter 6 (‘Personal Signatures in Art’) not only describes how this notion arose, but also asks why personal signatures exist in the first place. What is it about the creative process which makes personal signatures near-inevitable? Even exploratory creativity, which is the most highly constrained of all three types, leaves many points for individual choice. Were that not so, each artistic style would allow only one instantiation: a single painting, sculpture, fugue ... in that particular style. And because of certain general features of mental information-processing, necessitated by the finitude of our minds, it is highly probable that individual artists will develop idiosyncratic habits of working which distinguish their art from that of other artists—even those exploring the same style. Combinational creativity is more free, less predictable. But here too, general psychological features (affecting the perception of relevance, for example) will engender patterns of thought that are specific to the individual artist. A further question raised in Chapter 6 is whether personal signatures are not merely highly probable, but wholly inevitable. Why have those f ine artists who (in a twentieth-century reaction against Romanticism) have deliberately tried to avoid the p ersonal signature been only partially successful at doing so? And why have they failed even when turning to impersonal machines for help? In particular, is it possible for a human artist to lose his personal signature by engaging in a type of computer art wherein a robot is evolved (not specifically designed) to draw aesthetically acceptable marks that don’t betray his authorship? One int ernationally famous artist is already trying to do precisely this—but it’s by no means clear whether he will, or even could, succeed. Using a robot, as opposed to a computer screen, is not mere gimmickry. For it makes it possible for serendipitous events to happen, wherein the robot interacts with some previously unconsidered aspect of its physical environment. In other words, the drawings that result needn’t be wholly dependent on exploring the space of possibilities predefined by the program (including its mutation rules). In principle, some fundamental transformation could occur—comparable to evolving a first-time eye, not just an improved eye. (A first-time sensor has already been evolved in practice , by someone involved in the artoriented robotics project being considered here: Bird and Layzell 2002.) In short, something deeply surprising could conceivably emerge from the evolutionary processes underlying the robot’s behaviour (cf. Boden,8 Introduction in preparation). Such a result isn’t guaranteed, and is even pretty improbable—but it is possible. One might think that the desired loss of signature must be possible too. After all, the robot’s final line-drawing behaviour will be the end point of a process involving myriad random mutations. Indeed, one might think that this randomness makes it impossible for the evolving robot not to lose the artist’s telltale sign. Chapter 6 shows that this issue is not so easily decided. The problem is that the signature-fleeing artist himself will have the f inal say in choosing the criteria of selection (the ‘fitness function’) that are used at each generation to pick the ‘best’ mutants for further evolution. His chances of success—that is, of enabling the robot to lose his personal mark—depend on the degree to which our (and his) aesthetic preferences rest on basic, culture-free, properties as opposed to culturally, or even personally, specific styles. These basic properties might include some of the affordances favoured in craftwork (see Chapter 4), but could also include other features that are fundamental to visual perception. Certain fractal properties, for instance, might be naturally attractive. In short, this project raises empirical psychological questions as well as philosophical ones. Why ‘‘philosophical’’ ones? Well, references to robots making line drawings may raise the hackles of some readers: ‘‘These papers are supposed to be about creativity and art’’ they may grumble, ‘‘Robots, in principle, can have nothing to do with either’’. In other words, they believe that there can be no such thing as computer creativity ,and (a different, though related, point) that there can be no such thing as computer art . With respect to the latter claim, some philosophers justify their refusal to admit the possibility of computer art by defining ‘‘art’’ in exclusively human terms. Anthony O’Hear (1995), for example, insists that art involves some form of communication between one human being and another. For this to be possible, he says, artist and audience must share human experience. He would be willing to admit that computer art exists in the sense in which watercolour art, or marble art, do: that is, a computer can be used as an artist’s medium. He’d probably allow, also, that a computer can be an artist’s tool, or aid—perhaps even an artist’s assistant (although that is more questionable: see Chapter 8). But if any ‘artwork’ is generated by the computer itself, by means of processes that are largely beyond the human artist’s control, then—for O’Hear—it isn’t really an artworkIntroduction 9 at all. It may happen to be visually/aurally arresting, decorative, or even beautiful. But to respond to it as an artwork is, he says, to be deceived. Even to see it as aesthetically valuable, he says, is to be largely misled. On discovering its provenance, our aesthetic satisfaction would—and should—decrease, even evaporate. (I have witnessed people making this sudden shift of evaluative attitude on several occasions.) O’Hear is not alone in such views. And the problem he raises remains even if one includes other ways, besides communication, in which human experience may be involved—for instance, where the artist aims to enable, facilitate, an d/or arouse certain experiences, rather than communicate them. It remains, also, if the type of experience one regards as aesthetically crucial involves emotion (a very common view, broadly known as expressionism in aesthetics). The problems remain because anyone who defines art in such a way that human experience and/or human creativity is essential to it must be sceptical about the notion of computer art. And the more the computer ‘artwork’ is generated by processes going on in the computer itself, the stronger their scepticism must be. At best, computer art will be seen as art at one remove, thanks entirely to its human instigation. Even if art is defined in terms of the natural , as opposed to the human , the notion of computer art will still be problematic. If, by contrast, art is defined in terms of properties of the art object that are not exclusively human and/or natural, talk of computer art might escape challenge. However, I shan’t offer any ‘non-human’ definition of art, designed to allow the inclusion of the computer-based varieties. Quite apart from the air of special pleading that would attend such a definition, it would require lengthy argument that would be out of place here. For the definition of art is a notoriously slippery matter, which often threatens to exclude works that many people regard as art—such as conceptual art, and certain items of craftwork: see Chapters 5 and 4, respectively. I’ll rely instead on the (undefined) common usage of ‘‘art’’, and on paradigm cases of it—from Fra Angelico’s delicate murals to Mark Rothko’s glowing colour constructions. The more problematic cases can be accepted as art to the extent that they show similarities to and continuities with the commonly accepted examples. One more point must be made before talk of computer art can be specifically defended. Namely, our intuitive concepts of art, if not our explicit definitions, typically see it as creative. Indeed, the link is so close that people often fail to realize, or anyway forget, that science and mathematics involve creativity too. This leads to a further problem in10 Introduction speaking of computer art, since many people insist that no computer can really be creative. They may be willing to grant that a machine may generate novel, surprising, and even arguably valuable results: lifelike and/or beautiful images, for example. But, they say, the creativity involved can be attributed only to the human being/s who made it behave in that way. This claim is usually grounded in arguments involving one or more key philosophical concepts that are (plausibly) assumed to be essential for creativity. These concern consciousness, intentionality, the role of ‘brain-stuff’ and/or embodiment, and membership of the human moral community. I’ve argued elsewhere that although the brain-stuff argument can be rejected, each of the others remains highly problematic (Boden 2004: 286–300). What’s more, they are problematic primarily because of the disagreements concerning these philosophical concepts themselves. If we understood intentionality better, or consciousness, we’d be in a better position to pronounce on whether or not computers can ‘‘really’’ be creative. Since these notoriously controversial problems remain unsolved, I nowhere claim that computers are ‘‘really’’ creative. If and when I mention creativity in computers I am asking what aesthetically interesting results can computers generate, and how? and Just what might lead someone to suggest that a particular computer systemis creative, or that its functioning is somehow similar to creativity in human beings? In that sense, I’m content to leave the question of ‘‘real’’ computer creativity open. And if art necessarily involves creativity—a reasonab le, if not a strictly provable, view—then (in that sense) I must leave the question of ‘‘real’’ computer art open too. So I shan’t try to prove that computer art can exist because it fits some favoured (and tendentious?) definition of art and/or of creativity. Instead, I’ll rely on two strategies to persuade sceptical readers that this isn’t an empty class. On the one hand, I’ll point out (in Chapters 7–11) many similarities and continuities between computer art and the more familiar varieties. On the other hand, I’ll mention some examples where the work of computer artists is taken seriously as art by aesthetes of an orthodox kind. For instance, I remark in Chapter 7 that a computer artwork was included in the Washington DC exhibition mounted in 2007 to celebrate the sixtieth anniversary of the ColorField painters: Rothko, Clyfford Still, Kenneth Noland, and the like (Edmonds 2007). Despite the welcome imprimatur of the Washington gallery (and many others, including the Tate), computer art is still largely unknownIntroduction 11 even to art lovers and aestheticians. So Chapter 7 (‘What Is Generative Art?’), co-authored with Ernest Edmonds, offers a novel taxonomy of work in this genre—along with an indication of the philosophical issues that attend the various categories. As well as distinguishing significantly different types of computer art, this taxonomy displays several connections between computer art and more established forms. Chapter 7 can therefore act as an introduction to the field for readers who haven’t yet encountered it—much as Chapter 5 can act as an introduction to conceptual art for those unfamiliar with it. By different ‘‘types’’ of computer art, in the context of Chapter 7, I mean different techniques for producing computer artworks and/or different types of experience on encountering them. But one might also distinguish these artworks by the differences in their physical implementation—which cut across the generative distinctions used to draw up the taxonomy. For instance, some computer artworks are framed ‘pictures’ hung on the wall. These may be unchanging images, both produced and printed by a computer program (e.g. Todd and Latham 1992). Or they may be ever-changing coloured patterns, the changes being prompted by the viewer’s movements—thanks to a minicamera and minicomputer hidden in the square perspex frame (Edmonds 2007). As Chapter 6 implied, a few involve physical robots. Whether attached to walls or ceiling, or ranging free over the floor, their movements have some intrinsic interest and/or produce results, such as sounds or line drawings, that the audience finds intriguing. Others are interactive CD-R oms , which provide differing experiences as a result of the viewer’s input (Leggett 1996). Yet others are static or (more usually) dynamic video projections, perhaps presented on a computer monitor or perhaps filling an entire wall. And some of these are virtual reality environments, a millennial form of trompe l’œil (a genre employed by artists since Roman times: Grau 2004) often projected onto all four walls, and maybe floor and ceiling too. Occasionally, it’s not only the audience’s eyes that are deceived, but their ears and (if special gloves are worn) their f ingertips too. Whereas all of those examples are located inside a building, whether an art gallery or someone’s home, others are exhibited in bustling city squares. In that case, the installations are typically huge: much more than human size. Being out-of-doors, their form may change as a result of weather conditions, as well as of the movements of the people passing by.12 Introduction One must add, however, that some computer artworks aren’t physically located at all. Rather, they exist on the Internet. (Thor Magnusson has suggested an additional entry for the taxonomy: N-Art, or Network art.) These works are accessed—and developed—by human beings located in physical space: staring at their PC screens, for instance, or using their mobile phones, or playing musical instruments while online. They may be altered, to some (highly variable) degree, by input coming from those individuals. But the artwork itself, even if there happens to be some physical installation at its core (which there may not be), isn’t really located anywhere—except in cyberspace. A prominent early case of Network art was Ken Goldberg’s Telegarden . Developed at the University of Southern Californa in 1995, this was installed in the Ars Electronica Centre (now renamed the Museum of the Future) in Linz, Austria, a year later; it ran non-stop for nine years, until being switched off in 2004. Unlike many N-art works, it did have a physical core: a garden filled with living plants, which were planted and watered by means of a robot arm. The garden’s progress could be monitored through images from an on-site camera. The movements of the robot arm were remotely directed by web-users all over the world: 9,000 people connected with it in its first year. Besides remarking on a wide range of ecological/environmental meditations prompted by this artwork (see < http://goldberg.berkeley.edu/garden/Ars/ > ), the users reported feelings of human community of a (distributed) type never experienced before (McLaughlin et al. 1997). The nearest analogy would be their prior experience, if any, of web-based ‘games’ involving huge numbers of players (Turkle 1995). The Telegarden example shows us that tricky ontological questions arise with respect to some computer artworks. Is the garden the artwork?; or the community of human users that’s been built up over the years?; or their comments and meditations, shared on the web alongside camera images of the plants?; or ... ? Again, consider the line-drawing robots mentioned in Chapter 6: are the robots the artwork, or is the artwork rather their drawings? Or perhaps both? Conceptual art can engender similar conundrums (or conundra, if you prefer!). The work called 42nd Parallel (described in Chapter 7) is said by its instigator—one can hardly say its maker—to consist in a geographically dispersed pattern of activity in the US postal system. As such, it isn’t clearly located either. Of course, tricky ontological problems can arise with respect to much more familiar forms of art than this (a classic discussion is: Goodman 1968). So ontology is one of theIntroduction 13 various philosophical/aesthetic dimensions on which this new category of art is related to ‘art as we know it’. One difference noted in the taxonomy is that between computerassisted or computer-aided art (CA-art) and computer-generated art (CG-art). (This distinction underlay my claim, above, that O’Hear might allow the possibility of computer-assisted art, though not of computer-generated art.) In CA-art, the human artist produces the artwork with some help from the computer, which is in principle nonessential. In CG-art, the artwork is produced by the computer itself, with minimal or zero interference from a human being. The terms ‘‘computer-assisted’’ and ‘‘computer-aided’’ art are normally used interchangeably, and the category of CA-art covers both. But one might want to make a further distinction here. A tool (e.g. a paintbrush or chisel) that’s wholly under the artist’s control is more readily thought of as an aid than as an assistant . And indeed, the examples of CA-art given in Chapter 7 involve off-the-shelf programs (Photoshop and video editors) used by the artist as tools in the production of many different artworks. But Chapter 8 (‘Agents and Creativity’) suggests that CA-art could also involve specially written programs, containing AI ‘‘agents’’ for some particular style of art. As this label implies, these would be conceptualized—and experienced—by their human users less as mere tools than as semi-autonomous assistants, capable of cooperating [ sic ] in the task at hand. AI agents in general have a significant degree of independence from the human being who is using the program. Indeed, they are often termed ‘‘autonomous’’ by AI researchers. There are two reasons for this. First, they are not deliberately called up by the human user, but are automatically triggered by specific cues: events occurring within the running of the program or in the environment (maybe including the user’s actions). And second, they are not amenable to interference from the user once they have started to run. Whereas some agents are relatively simple processes, comparable to a reflex knee-jerk, others are more like mini-minds. These can set and follow goals, and cooperate with partner-agents. For example, they can devise engagement schedules (avoiding conflicts with entries already in the user’s diary), book hotel rooms, and arrange for flights and car-hire—perhaps without bothering the user, or perhaps making suggestions for human ratification (Norman 1994). Some can even learn how to do better in future by inferring, or being told, why their suggestion was rejected (Mitchell et al. 1994: 87). Where such14 Introduction ‘mini-minds’ are concerned, the user’s illusion of having a quasiintelligent assistant can be fairly strong. Sometimes, the agent’s action is to send a message to the user. This may be a warning, saying that he/she has made a mistake or that some danger point is being approached. Or it may be a suggestion about what to do next: perhaps how to rectify the mistake, or avoid the danger. The user can then decide whether or not to heed the agent’s advice. The existing computer-art programs that are mentioned in Chapter 8 do not contain agents: they exemplify CG-art, not CA-art. They include (exploratory) programs for designing Palladian villas or Frank Lloyd Wright’s Prairie Houses, and for improvising jazz. Each of them, I suggest, could in principle be modified to form an agentive version. So too could large semantic networks—so as to help writers, whether comfortable in advertising studios or freezing in garrets, to find and develop conceptual associations (alias combinations). In practice, however, agent-based computer art is thin on the ground. The reason, I suspect, is that (with a caveat mentioned below) the more strongly the human user identifies him/herself as a creative artist, the less likely that they will want to rely on AI agents as design crutches. They may be happy to bite the bullet—indeed, to swallow it whole—and go down the route of CG-art. But that’s a different enterprise (one which could well involve agents working behind the scenes, like the diary-organizer mentioned above). In other words, CAartists may feel that an agentive CA-system would compromise their own artistic autonomy, integrity, or authenticity: they want computer aids (tools), not computer assistants. The caveat, here, is that some CA-artists might be perfectly happy to have the ‘‘A’’ mean ‘‘assistant’’, given that some non-computer artists rely heavily on human assistants in their work. Examples range from the Renaissance masters to conceptual artists such as Sol LeWitt and Jeff Koons (see Chapter 5). The sixteenth-century masters would sometimes merely sketch the outlines of the picture and paint the faces of the key people depicted in it, leaving the drapery and/or background to be executed by their apprentices. And the conceptual artists all underplayed the role of personal art-making skills, if not of creativity, in their work; Koons, for instance, became notorious for employing others to paint ‘his’ canvasses. So for a CA-artist who sympathizes with that general art movement, there’s no reason to avoid using computer agents as assistants.Introduction 15 Nor is there reason to avoid this if the creative activity is thought of as practical design, as opposed to art. For instance, the computer-assisted design (CAD) programs used today by professional engineers and jobbing architects can monitor the provisional decisions of the user, identifying mistakes and sometimes offering suggestions. If a design for a building had a potential structural weakness, for instance, an engineering-wise CAD program could warn the architect of that fact; it might also be able to suggest how the fault could be put right. Or suppose that an architect’s client had requested a building like a Prairie House, and that there were no CG-art program capable of designing one entire: in that case, the architect might find it helpful [ sic ]tohavea set of Prairie-agents, to be consulted at particular choice points during his design work. But the results wouldn’t be presented to the world as ‘‘art’’. Moreover, no self-styled creative architect would be spending his/her time copying Lloyd Wright. I said, above, that some computer artists may be loath to use computer assistants for fear of jeopardizing their own autonomy, integrity, or authenticity. And some readers will surely sympathize, feeling that concepts such as these can have no place in computer-based art—least of all, where the artwork is generated by wholly automatic processes. On their view, artists who adopt a CG-art methodology thereby abandon any claim to such epithets. The next two chapters address these issues. As for the first member of the problematic trio of concepts, some computer artists justify the value of their work in part by citing the ‘‘autonomy’’ of the computerized system concerned. They have inherited that terminology from the AI researchers whose methods they are exploiting. We’ve seen, for example, that agents are commonly termed autonomous within the AI community. Critics may object that the fact that computer scientists speak in this way merely shows that their field doesn’t foster sensitivity to natural language. However, even if we ignore that objection and focus instead on the nature of the systems themselves, we must recognize that there are significantly different senses of ‘‘autonomy’’. If autonomy does have any aesthetic value, we need to know what type of autonomy is in question in a given case. Chapter 9 (‘Autonomy, Integrity, and Computer Art’) shows that the various senses of autonomy are distinguished not by mere nuances, but by differences that include some seemingly radical oppositions. So natural autonomy includes biological homeostasis, psycho-physiological reflexes, various kinds of animal behaviour, and human freedom. Likewise, the autonomy that characterizes (some) computer systems is16 Introduction comparable to those very different phenomena. (We’ve seen already that computerized agents are sometimes like reflexes, and sometimes like goal-seeking mini-minds.) Different types of computing methodology are best suited to achieve different types of autonomy.
COMPUTER COMBINATIONS Well, think of combinational creativity first. In one sense, this is easy to model on a computer. For nothing is simpler than picking out two ideas (two data structures) and putting them alongside each other. This can even be done with some subtlety, using connectionist methods (outlined in Boden 2004: ch. 6). In short: a computer could merrily produce novel combinations till Kingdom come. But would they be of any interest? We saw, above, that combining ideas creatively isn’t like shaking marbles in a bag. The marbles have to come together because there is some intelligible, though previously unnoticed, link between them which we value because it is interesting—illuminating, thought-provoking, humorous ... —in some way. (Think sleep and knitting, again.) We saw also that combinational creativity typically requires a very rich store of knowledge, of manyCreativity in a Nutshell 37 different kinds, and the ability to form links of many different types. (Here, think politicians and newts again.) And we don’t only form links, we evaluate them. For instance, we can recognize that a joke is ‘‘in bad taste’’. In other words: yes, the links that the joker is suggesting are actually there (so it is a real joke). But there are other links there also, which connect the ideas with sorrow, humiliation, or tragedy. The joker should have noticed them, and should have refrained from reminding us of them. For a computer to make a subtle combinational joke, never mind to assess its tastefulness, would require (1) a database with a richness comparable to ours, and (2) methods of link making (and link evaluating) comparable in subtlety with ours. In principle, this isn’t impossible. After all, the human mind/brain doesn’t do it by magic. But don’t hold your breath! The best example of computer-based combinational creativity so far is a program called JAPE, which makes punning jokes of a general type that’s familiar to every 8-year-old (see Boden 2004: ch. 12). But making a one-off jest is usually more demanding. Ask yourself, for instance, what Jane Austen had to know in order to write the opening sentence of Pride and Prejudice : ‘‘It is a truth universally acknowledged that a single man in possession of a good fortune must be in want of a wife.’’ (And why, exactly, is it funny?)
A creative idea is one that is new , surprising ,and valuable (Boden 2004). The term ‘‘idea’’ is a shorthand, here. In art, the new idea sometimes is an ‘‘idea’’ in the normal sense: a concept, if you prefer. But it need not be. It may be a method for producing artefacts (a new type of paintbrush, a revolutionary camera or developing technique, or a novel way of casting bronze). Or it may be a general style of painting, or sculpting. Or it may be a musical composition, or passing harmony; or a new dance step or choreography ... andsoon.InSectionsIVandV, I’ll mention a wide range of creative ‘‘ideas’’ drawn from conceptual art. Besides the ambiguity of ‘‘idea’’, each of the three criteria of creativity is ambiguous. That’s largely why disagreements about creativity are often carried on at cross-purposes.Creativity and Conceptual Art 71 There are two importantly different senses of ‘‘novel’’. On the one hand, an idea may be new to the person who had it: it’s a first-time occurrence within their particular mental biography. Let’s call this P-creativity, where the ‘‘P stands’’ both for ‘‘person’’ and for ‘‘psychological’’. On the other hand, an idea may be—so far as is known—new with respect to the whole of human history: that is, it’s H-creative. From the psychological point of view, which seeks to understand how creativity happens and how it’s even possible, P-creativity is the more important concept. For every instance of H-creativity is a special case of P-creativity. (If it’s the first ocurrence in human history, then it must also be the first occurrence in the mind of its originator.) From the historical point of view, H-creativity is the focus of special interest. But since every H-creative idea is P-creative too, we can always ask what type of P-creativity was involved. This applies to the twentiethcentury emergence of conceptual art, just as it does to any other artistic movement. The second criterion, surprise, has three meanings. One may be surprised because something is statistically unusual, so contrary to common-sense expectations—like an outsider winning the Derby. Or one may be surprised because one hadn’t realized that the new idea had been a possibility all along—like discovering a beautiful village tucked away in a hollow between two spurs of the motorway. (Its location had always been marked on the map, but one hadn’t examined the whole map closely.) Third, one may be surprised by something that one had previously thought impossible, and which one still sees as utterly counter-intuitive. Here, think of the events categorized by the religious as miracles, or imagine the impact on non-physicists of the introduction of wireless, or television. The third criterion, being ‘‘valuable’’, has many different meanings. For various reasons, these can’t be wholly pinned down. What’s valuable in music isn’t necessarily valuable in, or even applicable to, architecture. What’s valuable in a baroque fugue may not be valuable in the blues. And what’s thought valuable in the 1960s may be scorned in the 1970s. As that remark suggests, values can change (sometimes, virtually overnight) as a result of shifts in fashion—some deliberately engineered for commercial purposes, some arising from unpredictable events (such as what an admired ‘‘celebrity’’ chooses to wear to a party). There may be some universal or near-universal values: symmetry and shininess, perhaps? (Boden, 2006 8.iv.c). But even these can be deliberately transgressed, and their opposites admired in72 Creativity and Conceptual Art their stead (think of the highly asymmetrical architecture of Daniel Libeskind). One class of values merits special mention here, namely, what ecological psychologists call ‘‘affordances’’ (Gibson 1966, 1979). These are naturally evolved tendencies to behave towards a perceived feature in a particular way. Some are positive: affordances suggesting opportunities for locomotion, for feeding, for stroking, for courting ... and so on. Others are negative, such as affordances eliciting fear or disgust. (The latter have presumably evolved to prevent us, and other animals, from eating rotting and/or contaminated food.) The ‘‘crafts’’ in general depend on the elicitation of positive affordances, which is why they are universal,relativelyunvarying,and—unlike‘‘art’’—capableofspeaking for themselves (Boden 2000). In other words, craftworks can be appreciated without specific cultural knowledge, whereas artworks cannot. Even if an artwork does exploit inborn affordances (as many do), it’s primarily interpreted as a moment situated within a particular cultural context. The defining characteristic of a new artistic movement is that certain aspects of a wide range of artworks are now valued within a certain culture (or subculture) which weren’t valued before. Usually, many—even most—of the previous values are retained. Occasionally, however, almost none is retained. As we’ll see, the latter applies to the twentiethcentury movement known as conceptual art. III. THE THREE TYPES OF CREATIVITY The three types of surprise listed above correspond to three types of creativity: combinational, exploratory, and transformational (Boden 2004: chs. 3–6). They’re distinguished by the types of psychological process that are involved in generating the new idea. The exercise and appreciation of each of these forms of creativity depends upon specific cultural knowledge. Someone from a different culture may not even be able to recognize the novelty involved, and a fortiori they may not be able to understand/appreciate it. In the context of conceptual art, it’s worth pointing out that ‘‘someone from a different culture’’ needn’t be a foreigner: they may be your next-door neighbour. If so, they’ll have to undergo a learning process if they’re ever to understand the novelty and to judge the aesthetic value. Combinational creativity involves the generation of unfamiliar (and interesting) combinations of familiar ideas. In general, it gives rise toCreativity and Conceptual Art 73 the first type of surprise mentioned above. Just as one doesn’t expect the outsider to win the Derby, because that doesn’t normally happen, so one doesn’t expect ideas X and Y to be combined, because they seem to be mutually irrelevant. Everyday examples of combinational creativity include visual collage (in advertisements and MTV videos, for instance); much poetic imagery; all types of analogy (verbal, visual, or musical); and the unexpected juxtapositions of ideas found in political cartoons in newspapers. Exploratory and transformational creativity are different. They’re both grounded in some previously existing, and culturally accepted, structured style of thinking—what I call a ‘‘conceptual space’’. Of course, combinational creativity too depends on a shared conceptual base—but this is, potentially, the entire range of concepts and world knowledge in someone’s mind. A conceptual space is both more limited and more tightly structured. It may be a board game, for example (chess or Go, perhaps), or a particular type of music or sculpture. In exploratory creativity, the existing stylistic rules or conventions are used to generate novel structures (ideas), whose possibility may or may not have been realized before the exploration took place. (You may or may not have had some reasons to expect to find a village nestling between the motorways.) It can also involve the search for, and testing of, the specific stylistic limits concerned. Just which types of structure can be generated within this space, and which cannot? Transformational creativity is what leads to ‘‘impossibilist’’ surprise. The reason is that some defining dimension of the style, or conceptual space, is altered—so that structures can now be generated which could not be generated before. Imagine altering the rule of chess which says that pawns can’t jump over other pieces: they’re now allowed to do this, as knights always were. The result would be that some games of chess could now be played which were literally impossible before. The greater the alteration, and the more fundamental the stylistic dimension concerned, the greater the shock of impossibilist surprise. However, not every dimension will have been changed. (Otherwise, why call it a new form of chess ?) So there will be both structural continuities and structural discontinuties between the untransformed space and its seemingly impossible successor. If some feature of the game which you enjoyed before the change is retained, you’ll find something to enjoy in the transformed version. You may, however, be so averse to jumping pawns—perhaps they make you feel giddy?

Thefield of Artificial Intelligence (AI) really came into existence with the birth of computers in and around the 1940s and 1950s. For the earlier period of its development, attention was clearly focused on getting computers to do things that, if a human did them, would be regarded as intelligent. Essentially, this involved trying to get computers to copy humans in some or all aspects of their behaviour. In the 1960s and 1970s this opened up a philosophical discussion as to just how close to a human brain a computer could be, and whether any differences that arose were really important. This period– referred to as ‘classical AI’ in this bookwas, however, rather limited in its potential. In the 1980s and 1990s we saw a whole new approach, a sort of bottom- up attack on the problem, effectively building artificial brains to bring about AI. This completely opened up the possibilities and created a whole new set of questions. No longer was AI restricted to merely copying human intelligence– now it could be intelligent in its own way. In some cases it could still be brought about by mimicking the way a human brain performed, but now it had the potential to be bigger, faster and better. The philosophical consequence of this was that now an artificial brain could potentially outperform a human brain. In more recent years thefield has really taken off. Real- world applications of AI, particularly in thefinance, manufacturing and military sectors, are performing in ways with which the human brain simply cannot compete. Artificial brains are now being given their own body, with which to perceive the world in their own way and to move around in it and modify it as they seefit. Theyviii  PREFACE  are being given the ability to learn, adapt and carry out their wishes with regard to humans. This raises all sorts of issues for the future. The aim of this book has been to realise a truly modern and upto-date look at thefield of AI in its entirety. Classical AI is certainly looked at, but only as part of the total area. Modern AI is also considered with equal balance. In particular, some of the very latest research into embodied AI and growing biological AI is also discussed. The intention is to provide a readable basic guide to the field of AI today– to see where it has come from and where it may be going. The main aim is to provide an introduction for someone not at all familiar with the topic. However, it may well also be of interest to those already involved in science, technology and even computing, who perhaps need to catch up with recent developments. I would like to thank many people for their help in putting this book together. In particular, my colleagues and research students at the University of Reading, especially Mark Gasson, Ben Hutt, Iain Goodhew, Jim Wyatt, Huma Shah and Carole Leppard, all of whom have contributed significantly to the work described. I also wish to extend my gratitude to Andy Humphries of Taylor & Francis, who has pushed me to get the book completed despite many other conflicting calls on my time. Finally, I wish to thank my wife, Irena, for her patience, and my kids, Maddi and James, for their criticism. Kevin Warwick Reading, January 2011INTRODUCTION SYNOPSIS In this opening chapter a brief overview is given of what the book is about, its aims and potential readership. A glimpse is also given of how the subject area has developed over the years, including mention of the key movers, important issues and breakthroughs. Essentially, the chapter provides a gentle helping hand to guide new readers into the subject. This chapter is not a necessity for those already familiar with the subject of AI, but nevertheless it could stimulate some thoughts or provide useful nuggets of information. INTRODUCTION The book is written as an introductory course text in Artificial Intelligence (AI), to provide material for a first course for students specialising in areas such as computer science, engineering and cybernetics. However, it can act as a background or reference text for all interested students, particularly in other branches of science and technology. It may also be useful as an introductory text for A-  level students and even members of the general public who wish to get an overview of the field in an easily digestible form. The subject area has shifted dramatically in the last few years and the text is intended to give a modern view of the subject. Classical AI techniques are certainly covered, but in a limited way – the goal is an all-  encompassing, modern text. The content of the book covers aspects of AI involving philosophy, technology and basic methods.

SENSING AND MOVEMENT Intelligence is an important part of an individual’s make-  up. However, this depends not on their brain alone, but also on how it senses and activates things in the world around it. How the world is perceived by that individual depends on the functioning of their brain, their senses and their actuators (e.g. muscles). Humans have five senses: vision, hearing, taste, touch and smell. This gives us a limited range of inputs. We cannot sense many WHAT IS INTELLIGENCE?  17 signal frequencies; for example, we do not have ultraviolet, ultrasonic or X-  ray sensory input. Our perception of the world is therefore quite limited – there is a lot going on around us that we have no idea about because we cannot sense it. At the same time, another creature or a machine with different senses could be witnessing a major event which a human would know nothing about. A being’s senses need to be taken into account when considering intelligence. Just because a being is not the same as a human – for example, if it senses the world in a different way – this does not necessarily make it better or worse, merely different. The success of a being depends on it performing well, or at least adequately, in its own environment. Intelligence plays a critical part in this success. Different creatures and machines succeed in their own way. We should not consider that humans are the only intelligent beings on Earth; rather, we need to have an open concept of intelligence to include a breadth of human and non-  human possibilities. The story is much the same in terms of movement. Humans are able to manipulate the world in various ways and to move around within it. Each being has different abilities in this respect, depending on what their life role is. It is not appropriate to say something is not (or less) intelligent because it cannot do some specific task. For example, it would be wrong to say that a creature or machine is stupid because it cannot make a cup of tea – this is a very human task. Only in comparing humans should such a task even be considered as some form of measure. Based on this broadening discussion, a more general definition of intelligence might be: ‘The variety of information-  processing processes that collectively enable a being to autonomously pursue its survival.’ With this as a basis, not only can intelligence in animals and machines be respected and studied for what it is, but also intelligence in humans can be put into perspective in terms of merely serving as one example. Clearly, this definition is open to much criticism, but it is felt to be a substantial improvement on those given at the start of the chapter, which have far too strong a human bias to them. It could be argued that the earlier definitions are not explaining intelligence in general, but only human intelligence.18  ARTIFICIAL INTELLIGENCE: THE BASICS  ALIEN VIEW An interesting way to consider the problem of intelligence is to think of yourself as an alien from another planet, inspecting Earth from afar. What would you consider the intelligent life forms on Earth to be? Could they be vehicles, networks, water, clouds, animals, bacteria, televisions? Presumably you would apply some tests based on your own concepts of life form and intelligence. So, if you are living on a planet for which the main sensory input is a type of infrared signal, then your view of Earth may well not include humans as an intelligent life form. Even considering what we as humans define as being the basics of life could lead to apparently strange conclusions. From basic biology we could consider the following as indications: nutrition, excretion, movement, growth, irritability, respiration, production (production rather than reproduction as humans produce, they do not ‘reproduce’ other than through cloning, which is ethically questionable). From an alien standpoint, even a telephone exchange or communications network satisfies these qualities of life – perhaps much more obviously than humans do – merely in terms of electrical pulses rather than chemical. From an alien viewpoint it could be concluded (even now) that a complex global networked intelligence on Earth was being served by small drone-  like simpler beings – humans. SUBJECTIVE INTELLIGENCE Intelligence is an extremely complex, multi-  faceted entity. In each being it consists of many different aspects. Intelligence is also subjective in terms of the group by which it is being viewed and the group being viewed. For any particular group that is considering intelligence, what are and what are not regarded as intelligent acts are dependent on the views of that group and are steeped in the social and cultural trappings of its members. When a puppy walks by the side of a person, this could be considered to be an intelligent thing to do or simply as the puppy satisfying a trivial programmed goal. When a human is able to rapidly calculate answers to mathematical questions or accurately WHAT IS INTELLIGENCE?  19 remember a series of facts on a particular topic, these could be regarded as intelligent acts – indeed the person could be called a ‘mastermind’ – or they could be regarded as a mere entertainment exercise. With differences between species the problem is exacerbated due to their different mental and physical capabilities and requirements. For humans studying different species (I include machines here) it is therefore important to try to recognise aspects of intelligence for what they are worth within that species rather than merely in terms of how they compare to aspects of human intelligence. Between humans we need to try and retain a scientific basis for our analysis of intelligence rather than to pamper to social stereotypes. For example, why is it that knowledge about politics, classical music or fine art is seen by some to be more indicative of intelligence than knowledge about football, pop music or pornography? Why is it that playing music by Mozart to a baby while still in the womb is considered, by some, to make the baby more intelligent, whereas playing music by the Rolling Stones is considered to be dangerous? Is there any scientific basis at all for such conclusions? I think not. Where are the conclusive scientific studies that have shown these things to be so? There are none. Unfortunately, we can quickly run into the problem previously mentioned, in that we already have a conclusion and we try to fit certain observations to match that conclusion and ignore others that do not match. If you wish to succeed at school or university, it is better (I take these merely as examples) to learn about fine art or classical music rather than football or pop music as these latter subjects can be seen as disruptive or a complete waste of time. From those who succeed in these areas of education will come the teachers and professors of the future who, in turn, because of the subjective nature of intelligence, will value those who toe the line and follow the lead of learning about fine art or classical music – those who perform well in the areas considered to be proper by the teachers themselves, who define the subject areas. And so it goes on. A strong social bias runs through such human educational systems and this can result in completely different values associated with subject areas. An individual can be regarded by others as being stupid simply because they do not know particular facts, 20  ARTIFICIAL INTELLIGENCE: THE BASICS  cannot carry out specific mathematical calculations or deal with some aspect of everyday life. Clearly, this is merely representative of one aspect of their intelligence – nothing more and nothing less. Despite this, humans often tend to use the same approach to make comparisons with other creatures or machines. Sometimes we do not give value to non-  human abilities, partly because we do not understand them. Conversely, we give value to animals copying some aspect of human abilities – for example, some consider dolphins to be intelligent simply because they do some tricks and are friendly to humans, whereas sharks are sometimes regarded as mindless killing machines because humans do not necessarily have the same mind set and values as a shark. Each individual has their own concept of intelligence with which they can measure others, both human and non-  human, in order to make comparisons – often to come to the conclusion that one individual is more or less intelligent than another. A group’s view of intelligence arises from a consensus between individuals who hold similar social and cultural beliefs and share common assumptions. Everyone’s concept also partly reflects their own personal qualities. When assessing the intelligence of a non-  human, possibly a machine, if we wish to put it down and claim in some way that it is not as good as a human, then we can certainly make comparisons of the non-  human’s abilities in a field in which humans perform well. We can, of course, compare human abilities with a non-  human in a field in which the non-  human performs well – however, the result would not be so good for humans, so we don’t tend to do such a thing. In assessing the intelligence of an individual we really need to get to grips with the physical make-  up of that individual, their mental make-  up, their social requirements (if any) and the environment in which they live and perform.

THE CHINESE ROOM PROBLEM The Chinese room is the scene for an argument originated by John Searle in an attempt to show that a symbol-  processing machine (a computer) can never be properly described as having a  mind  or understanding  or being  conscious , no matter how intelligently it may behave. It has become a cornerstone argument in the philosophy of AI, with researchers either supporting his case or attempting to provide counter arguments. Let us start by considering the argument itself. A computer (inside a room) takes Chinese characters as input and follows the instructions of a program to produce other Chinese characters, which it presents as output. The computer does this so convincingly that it comfortably convinces an external human Chinese speaker that it is itself a human Chinese speaker – effectively it passes the Turing Test (discussed in a later section), it fools another human into believing that it is, itself, human. It could be argued by a supporter of strong AI that the computer understands  Chinese. However, Searle argues that if the machine doesn’t have understanding  we cannot describe what the machine is doing as thinking . If this is the case then because it does not think, it does not have a mind  in anything like the normal sense of the word. Therefore, ‘strong AI’ is mistaken. Consider that you are in a closed room and that you (an English speaker who understands no Chinese) have a rule book with an English version of the same program. You can receive Chinese characters, process them according to the instructions, and as a result you produce Chinese characters as output. As the computer has convinced a human Chinese speaker that it is itself a Chinese speaker it is fair to deduce that you will be able to do so as well. There is in essence no difference between the computer’s role in the first case and the role you play in the latter. Each is simply following a program which simulates intelligent behaviour. Yet (as we have presumed) you do not understand a word of Chinese, THE PHILOSOPHY OF AI  73 you are merely following instructions. Since you do not understand Chinese we can infer that the computer does not understand Chinese either – as both you and the computer perform exactly the same function. The conclusion drawn by Searle is therefore that running a computer program does not generate understanding. THE EMERGENCE OF CONSCIOUSNESS Searle’s argument is essentially that you (a human) have something more than the machine; you have a mind which could learn to understand Chinese and that your mind is realised through the type of brain that you have. Searle said: ‘The [human] brain is an organ. Consciousness [and understanding] is caused by lower-  level neuronal processes in the brain and is itself a feature of the brain. It is an emergent property of the brain.’ He continued: ‘Consciousness is not a property of any individual elements and it cannot be explained simply as a summation of the properties of those elements.’ He concluded: ‘Computers are useful devices for simulating brain processes. But the simulation of mental states is no more a mental state than the simulation of an explosion is itself an explosion.’ The very last line (Searle’s conclusion) here is importantly and appropriately refuting the concept of strong AI – much as was discussed earlier. However, in the argument made, Searle opens up a number of other important considerations. First is the concept that you (a human) have something extra that the computer does not have (consciousness) and that this comes about as an emergent property of your brain – through your human neurons and their connections! This could be seen as epiphenomenal, in that there are ‘properties’ in human neurons that give rise to the mind, but these properties cannot be detected by anyone outside the mind, otherwise they could possibly be simulated in a computer, thus realising strong AI. These extra differences in the human brain are perhaps the qualia referred to by Penrose. One point here is that this is a good example of an argument in AI in which human intelligence is seen to be something special. It appears that even if we can’t measure it, the human brain is deemed 74  ARTIFICIAL INTELLIGENCE: THE BASICS  to have something more than a machine brain. The argument is human-  centric. It is concerned with a human language, with all the nuances and life experiences that that conjures up. Without having lived a human life, could a machine possibly understand  such a language in the same way as a human? This is indeed Searle’s point – no matter how much the computer is used in an attempt to copy the human brain, it will never be exactly the same – unless perhaps it is itself made up of human neurons and experiences some aspects of human life. The Chinese room argument can be refuted in a number of ways. As an example, the argument can be turned on its head and posed in a favourable way for a machine by considering a machine code communication – with exactly the same type of argument. You now have to follow a set of instructions with regard to machine code rather than Chinese. On the basis that no matter what you might learn, the machine code will still mean nothing to you, you will not understand  it, whereas, for all we know, a computer may well understand  the machine code. The end conclusion of such an argument would be that while a machine can be conscious, it is not possible for a human to be conscious. Searle has used his Chinese room argument in a number of different ways. He has said that while ‘humans have beliefs, thermostats and adding machines do not’ or (as discussed earlier) ‘if a shoe is not conscious then how can a computer be conscious?’. As indicated earlier, the exact same logic would argue that if a cabbage is not conscious then how can a human be conscious? Perhaps the most important aspect of human understanding and consciousness to conclude from this is that they are likely (as Searle postulated) emergent properties from the collective behaviour of human neurons. We will investigate this further, with intriguing consequences, in Chapter 5. TECHNOLOGICAL SINGULARITY One of the interesting and vitally important features to be gleaned from the study of machine intelligence is its potential not simply to be the same as, but to surpass human intelligence at some stage. The argument goes that it is intelligence that has put humans in THE PHILOSOPHY OF AI  75 their relatively powerful position on Earth and if something comes along that is more intelligent then this could pose a threat to human dominance. Already, computers outperform humans in a number of ways – aspects of mathematics, memory, sensory faculties, etc. Perhaps it is just a matter of time before a superintelligent machine appears, which can then design and produce even more superintelligent machines and so on. Such a situation, where humans could lose control, was referred to as the ‘technological singularity’ by Vinge in 1993. He said: ‘Within 30 years we will have the technological means to create superhuman intelligence.’ Moravec contributed: ‘Robots will match human intelligence in 50 years then exceed it – they will become our Mind Children.’ Because of this potential threat some people interestingly turn (for safety?) to the three laws of robotics , introduced by the science fiction writer Isaac Asimov, as though they have some scientific basis. The laws are: 1  A robot may not injure a human being or through inaction allow a human being to come to harm. 2  A robot must obey the orders given by a human unless this conf licts with law 1. 3  A robot must protect its own existence unless this conflicts with laws 1 or 2.

represented after all the visual processing has been taken into account. Rather it is the final product or overview of reality at a point of advanced perceptual processing more anterior to the primary visual cortex. Finally, it has been noted that deafferented (disconnected) neurones in area V1 of the macaque become reactivated shortly after lesioning. This is possibly due to collateral (alongside) connections from other cells at the same level, which allows other cells to extrapolate the conscious visual presentation without increasing the actual sensory detection (see the discussion in Spillmann, 2009 ). However, there is a limit to this reactivation in the case of extensive damage. This discussion is returned to in Chapter 9  on consciousness. Although patients with small scotomas and quadrantanopia (leading to small areas of primary visual f ield disruption) do not ‘see’ the impaired sensation as blacked-out patches, objects nevertheless disappear from view if they fall within the area of the damaged or disconnected primary visual cortex. Patients such as the one described in Box 2.1  report a dulling of the visual sensation in the area associated with the loss. In following the pathway of visual information from the retina to the primary visual cortex (see Figure 2.1 ), visual information first strikes the retina in the way that a signal might strike the curved dish of a radar scanner. Information coming in from the left hits the right side of the retina (radar dish). In this way, visual information on the left side of the viewer is received by the right side of both eyes and is transferred to the right brain hemisphere. This means that the bundles of axons (or optic nerve) which project from the right side of the left eye  have to cross over to the right hemisphere at the optic chiasm . A similar journey is taken by information that hits the left side of each retina from the right visual f ield, only in this case the information goes to the left hemisphere (it is best to draw a diagram, but left visual space goes to the right hemisphere and right visual space to the left hemisphere). These pathways may be traced out using Figure 2.1 . A cardinal rule is therefore that when there is a disorder of visual sensation which affects one side of the visual field it can often be assumed that the damage causing the problem is in the contralateral  or opposite brain hemisphere. As indicated, the main  pathway responsible for visual perception travels from the retina to the thalamus – more specifically the lateral geniculate nucleus of the thalamus  (LGN) on each side. The synapses at the thalamus have a one-to-one relationship with the cells that map the visual input at the retina. From the LGN the situation becomes more complex, since each of the two projections (left and right hemisphere) further subdivide from the thalamus into the Optic chiasm  is where the optic nerve projects to the same and opposite hemisphere. For example, this allows the left side of the retina to pass across to the left hemisphere.30  Disorders of Perception LR L a R LGN M ey er loop Optic radiation s sw eep f orw ar d within the t emporal lobe ending belo w the calcar ine ssur e d c f b e Looking do wn on a hor iz ontal slice Optic chiasm situat ed abo ve pituitar y gland Optic radiations tr av el via the par ietal lobe ending abo v e the calcanic ssur e a V1 ar ea 1 7 str iat e or pr imar y visual cor te x Optic chiasm LGN b c d e f Optic radiation s via par ietal lobe c b a d M ey er loop: optic radiations via t emporal lobe optic radiations  as they head for the primary visual cortex (see Figure 2.1 ). It is important at this stage to view a sagittal representation of the primary visual cortex ( Figure  2.2 ); this is the cortical destination of the neuronal projections shown in Figure  2.1 . This view of the brain can be realised if the brain is cut down its length along the longitudinal fissure, revealing the mesial aspect (the normally hidden inside surface ) of the brain. The important landmark sulcus (crease or valley) that is seen here, and is also on the posterior lateral surface of the occipital lobe, is referred to as the calcarine sulcus. Within each hemisphere the optic radiations from the LGN take two pathways as they travel towards the primary visual cortex ( striate cortex ). The optic radiations, Figure 2.1  The visual pathway showing the lesion sites necessary to produce hemianopia (loss of half the visual field), e.g. b or (c + d) and quadrantanopia, e.g. c, d or e. The pathway in bold illustrates the necessary disconnection for a homonymous (same for both eyes) right upper quadrantanopia assuming a lesion at d. The top diagram illustrates a horizontal section showing how a left lesion results in a loss within the right visual field and vice versa while the lower diagram (sagittal section) provides a useful mnemonic for working out that a temporal lobe lesion may cause an upper quadrantanopia due to a lesion disconnecting the optic radiations that travel through the temporal lobe via Meyer’s loop. A lesion within the upper pathway (parietal above temporal) would have resulted in a loss of visual information in the lower visual field; in the example this would cause a right lower quadrantanopia. The loss of visual information is, of course, usually less precise than a half or a quarter, as indicated in the legend. The situation of the lesion affecting the nasal pathway at f is less usual (see text). which travel via the parietal lobe, end up above  this calcarine sulcus. The second pathway via the temporal lobe involves radiations that terminate below  the calcarine sulcus. These last radiations initially sweep forward within the temporal lobe (Meyer’s loop), before travelling back below the calcarine sulcus to the inferior (lower) aspect of the primary visual cortex (striate cortex). These pathways can be easily remembered by the fact that the parietal lobe is topographically above the temporal lobe (above goes to above, below goes to below the calcarine sulcus). The optic radiations terminate in the primary visual cortex (Brodmann’s area 17) in an area already referred to as the striate cortex (see V1 in Figure 2.2 ). The primary visual cortex is referred to as ‘striate’, meaning striped, because the Disorders of Perception  31 Pr ecuneus Cuneus C alcar ine sulcus Lingual gyr us (V1) F usif or m gyr us Figure 2.2  An illustration of the area of destination for the optic radiations. Temporal lobe optic radiations end below the calcarine sulcus and optic radiation travelling through the parietal lobe end up above the calcarine sulcus. Illustrated is the approximate V1 area which corresponds to Brodmann’s area 17. This primary visual cortex is sometimes referred to as the striate cortex because, when the cortex is cut away revealing a cross-section, staining reveals cells which conjugate in clumps presenting a striped appearance. Imaging studies suggest that the fusiform gyrus provides an important pathway for visual information for the ‘what’ pathway. V1 is located in the lingual gyrus, derived from the Latin for ‘tongue’. cells in this area appear striped when stained. Again, as in the case of the thalamus, there is a mapping of the visual field areas within the primary visual cortex that represents the retina topographically in a one-to-one relationship with the visual field. Figure 2.1  shows the types of losses of sensation that can occur due to lesions at the various parts of the visual pathway. Broadly, large lesions to the left hemisphere result in difficulties in seeing the right visual field (right homonymous hemianopia), while lesions to the right hemisphere may result in a left homonymous hemianopia. Lesions to one of the optic radiations in isolation cause the quadrantanopias (approximately a quarter of the visual field missing). Lesions to the upper branch of the radiations which travel above cause the lowest quarter of the field to be affected. When patient CG ( Box 2.1 ) described a difficulty in seeing the left lower visual f ield (left lower quadrantanopia) this was suggestive of either a right parietal lesion or a right occipital lesion above the calcarine fissure. Had he claimed a difficulty in seeing in the left upper visual field (left upper quadrantanopia) then the clinician’s thoughts would have turned more towards a right temporal lobe or an inferior occipital lesion. In this way the impairments of the visual field provide clinically useful information for forming hypotheses about the cause of the patient’s other symptoms. A pituitary tumour may cause more unusual sensory disturbances (see f in Figure 2.1 ). The pituitary gland is just below the optic chiasm, and therefore the growth of a tumour can result in the two optic nerves being pressed from underneath affecting the nasal (inside) fibres prior to their crossing. This may lead to a number of effects, including loss of sensation to the nasal aspects of the retina (nearest the nose) resulting in a loss of some peripheral vision on both sides (illustrated in f in Figure 2.1 ). Strokes, tumours and traumatic brain injury  are the commonest causes of homonymous hemianopia (degradation of much of one half of the visual field on both sides). Needless to say, hemianopia is a significant handicap, especially in the initial stages of adaptation. Part of the problem relates to the subjective nature of this loss of sensation. There is no obvious demarcation from the patient’s point of view as to where good sensation ends and poor sensation begins (see Box 2.1 ). A patient who has a left hemisphere stroke may initially bump into doorways, tables and other obstacles on the right. However, within a few days the patient will often start to adapt to this problem by moving their eyes and head at an angle. In this manner, the reduced visual field is covering a more useful central position. Sometimes a patient’s sensitivity to visual stimuli is tested by a method referred to as ‘perimetry’. In this test a spherical frame is placed around the head of the patient. The frame has small lights placed at various points within the patient’s visual field. The examiner tests the patient’s visual field by switching on lights in various areas of the frame of the cage while the patient looks straight ahead. If a patient fails to detect a light it is assumed that there is a lack of sensation in that area. Alternatively, with a more rough and ready approach, the clinician will ask the patient if they can see their moving finger as they sit opposite the patient. The clinician will wiggle a finger or other object around the patient’s visual field while the patient covers one eye 32  Disorders of Perception and looks straight ahead at the clinician’s nose as they sit opposite. A quick mnemonic for learning the quadrantanopias can be achieved by placing an imaginary cross-section of the radar dish (superimposing an imaginary retina) in the area of the calcarine sulcus in vertical profile (see Figure  2.2 ). Damage to the upper part of the radar dish results in occluded vision for information entering from below in the visual field. Using this method it is easy to learn that damage to an upper area, e.g. parietal lobe (involving optic radiations that travel above the calcarine sulcus), may cause difficulty in seeing objects below the horizontal view. Using both the retina and calcarine ‘radar dishes’ one may quickly work out that a lesion in the left temporal lobe may cause a right upper quadrantanopia, an impaired ability to see in the right upper quadrant of visual space. Apart from the assessment of the presence or absence of detection of sensory information there are more subtle tests of sensation. Other disorders of sensation may occur through early lesions within the visual processing stream. The retina projects basic information concerning shape, luminance, form and light frequency or wavelength to the primary visual cortex and all these qualities may be impaired to varying degrees. Tests of sensory discrimination additionally include testing a patient for the presence or absence of light and the discrimination and detection of targets of different sizes and shapes. Also, tests that assess the detection of changes in spatial frequency and contrast sensitivity may be carried out (see Figure 2.13 ). Patients with difficulties in making these kinds of discriminations may refer to the stimuli as being like a blob (McCarthy and Warrington, 1990 , p. 23) and therefore fail to discriminate at this basic level of sensation discrimination. These disorders of sensation are further discussed under the topic of object recognition. It is important to mention the other sensory reception areas and their pathways. Apart from the paths of visual sensation there are two other pathways that cross over and are also dependent on the thalamus as a relay system. While there are ipsilateral auditory projections, the main auditory projections from the cochlear of the inner ear cross over to the medial geniculate body (MG) of the thalamus in the contralateral hemisphere before being projected on to the cortical area called Heschl’s gyrus  (see Figure 2.3 ). Heschl’s gyrus is the primary auditory cortex. From the primary auditory cortex of Heschl’s gyrus auditory information is further analysed within Wernicke’s area before its final analysis within the cortical association areas. In this way sensation from the left ear is mainly analysed in the contralateral right hemisphere cortex after being relayed via the thalamus. As described in the introductory chapter, the left hemisphere is usually dominant for language. In Chapter  6  on asymmetry there will be a further discussion of the right ear advantage for analysing verbal material. Because the right ear projects to the left hemisphere, verbal information presented to the right ear is processed more efficiently when there is competing verbal information in the other ear. Deficits in auditory sensation from cortical deafness are often associated with bilateral damage or disconnection of Heschl’s gyrus. Disconnection or bilateral damage to Heschl’s gyrus results in the patient responding like a deaf person; luckily, these bilateral lesions are very rare. Cortical deafness is the auditory equivalent to cortical blindness, which occurs when the visual cortex is extensively damaged or disconnected. Pure word deafness  is discussed in Chapter  7  on language disorders and is a bilateral lesion in which patients have a distorted or muffled perception of speech. Perception of somatosensory information similarly involves projections crossing over to the contralateral hemisphere, but this occurs within the pyramids of the brain stem. Again, this sensory information enters the thalamus before being analysed in the primary somatosensory area. In this way, what we feel or touch (haptic information) on the left side of our bodies is mostly analysed in the cortex within the right brain hemisphere. The primary somatosensory area is organised in a similar manner to the motor cortex (see Chapter 1 , Figures  1.9  and 1.10 ) with topographical representation of the various parts of the contralateral body so that damage to this area within the somatosensory cortex results in a lack of body sensation in the opposite side of the body. Left brain damage affects haptic sensation of right body areas and right brain damage affects haptic sensation on the left. Figure  2.3  shows a diagram of the thalamus and the various nuclei which are allocated to the different sensory areas. Patients with damage to primary sensation who are unable to report haptic (e.g. tactile sensation) information are referred to as suffering astereognosis . Astereognosis is no longer seen as a broad category of somatosensory disorders but is used to describe a lack of sensory differentiation. It is defined as impaired tactual spatial perception due to severe basic somatosensory perceptual impairment (Caselli, 1991 ). Like cortical blindness and cortical deafness, astereognosis involves bilateral damage or disconnection affecting the primary somatosensory areas. Caselli proposes that this can even refer to patients with severe peripheral neuropathies, such as those patients who suffer from Guillain Barre syndrome (Caselli, 2003 ). Astereognosis  is the tactile equivalent of hemianopia. The patient is denied sensation for a part of the body and is tested by recognising a series of objects through touch.Disorders of Perception  33 3,1,2 41 3,1,2 17 A DM VPL VA VL LG LP P MG 17 Figure 2.3  From the retina the visual information travels via the lateral geniculate nucleus (LGN) to Brodmann’s area 17, mostly between the two hemispheres medially (see top right medial representation). From the cochlear auditory system information travels via the medial geniculate (MG) nucleus to Heschl’s gyrus (BA 41), the primary auditory area within the Sylvian fissure. Haptic (touch) information crosses over in the brain stem from the body part via the ventroposterior lateral nucleus (VPL) of the thalamus and then to the somatosensory area in the postcentral gyrus (BA 3,1,4). Other nuclei which are referred to in later chapters include the anterior nucleus (A) and the dorsomedial nucleus (DM) in the context of memory function, the pulvinar (P) in relation to language, the ventral anterior nucleus (VA) and ventral lateral nucleus (VL) in relation to motor movements and projection to these areas from the basal ganglia. Study Questions • Persons with quadrantanopia may initially be unaware that they are not seeing part of their visual space. Why might this be? • Where might you expect to find a lesion in a person with a left upper quadrantanopia? • Most sensory systems cross over between one brain hemisphere and the other via a large wedge of axons called the corpus calossum. How and where does the somatosensory input to the brain and the motor output cross over? Does a sectioning of the corpus calossum stop the motor and somatosensory areas crossing over? 2.3  The Perceptual Process 2.3.1  An Introduction to the Perceptual Process In this section there is a description of a hierarchical process in which a feature analysis starts with the basic constituents of the visual stimulus in the primary visual cortex and ends with a more advanced analysis as information is processed further in its journey from the posterior occipital cortex towards the temporal cortex. This process, in its broad description, is not unlike Luria’s second unit that was introduced in Chapter 1 . It is now realised that there are separate specialised modules  that are added for shape/form, colour and motion, prior to the final percept being realised.

of occasions – the woman never talked to her again (ibid., p. 166). Some of these persons with developmental prosopagnosia learn to adapt and compensate for their disability by learning and using the way people walk, hairstyles, clothing, context and voices to recognise people (Kress and Daum, 2003 ). Both patients with acquired and developmental prosopagnosia may have difficulty in recognising their own reflection in the mirror. There is even an anecdote of such a patient with acquired  prosopagnosia (brain-damaged) apologising to his own reflection when he bumped into a mirror while shopping (Bauer, 1993 ). While such examples may have their amusement value, this disorder, as previously pointed out, is clearly a handicap for these patients in their social interactions. There are various ways in which persons may be identified. Their name may be retrieved, or their face may be recognised, or they may even be identified from biographical details such as a description of who they are or what they have done in the past. The model illustrated in Figure 2.26  is based on case studies described by Bruce and Young ( 1986 ) and modified by Francis and others ( 2004 ). Patients have been found who have difficulty in recognising faces but have no difficulty with names, while other patients have been found with the converse problem, being able to recognise a face but having difficulty retrieving the name. These last patients are an exaggeration of the common lament ‘I never forget a face, but I have trouble with names.’ The important issue here is that this double dissociation suggests that the processing of names and faces occurs separately. If you damage one process you do not necessarily damage another, and vice versa. Stages that are assumed to be associated with normal identification of a face are assumed to be sequential according to this model. The Bruce and Young model was influential when it was first proposed (1986; see Figure 2.26 ) and has spawned many similar models. In understanding this model, it is important to make the distinction between two units: the facial recognition unit  and the person identity nodes . The facial recognition unit represents the result of the processing of the structural features of a face and their immediate semantic features, e.g. looking respectable. There is the assumption that when a face is presented it is compared with a store of previously experienced faces. When there is a partial match with a configuration of a face that has been previously stored then there is a feeling of familiarity or a feeling of knowing  which increases with intensity as more facial information is matched and the number of possible faces is narrowed. Eventually, the face is recognised and the identity is retrieved from the person identity node. We know from our own experience that it is possible to judge a face as being familiar (face recognition unit match) while not knowing the person’s identity. Most of us have had that feeling at a party as we see someone Str uctural encoding F ace R ecognition Units (FR Us) Pe r son Identit y Nodes (PINs) C ognitiv e sys te m Name generation Figure 2.26  A simplified functional model of face and proper name processing adapted from Bruce and Young ( 1986 ) as modified by Francis et al. ( 2004 ), reproduced with permission. coming towards us, smiling at us with that look. Their facial features look familiar (facial recognition unit). We know we are going to be embarrassed as we frantically search our memory for the person’s identity which will allow us to know who they are, their occupation and  where we met them (person identity modes). Just before the person arrives, with relief, we realise who the person is – he lived down the road where we used to live – but there is the realisation that, although you know him well, you still can’t remember his name, which requires the name generation unit . According to this model, the product of the various units is passed to a cognitive system that represents the cumulative product of all the analysis (Riddoch, Johnston et al., 2008 ). The face recognition unit is assisted by structural encoding that includes the recognition of the face from different views ( viewer-centred  description). But it is assumed that faces are also coded in a more abstract form, which allows one to recognise a face, and that this is the case even if you have not seen the person from a particular orientation. Bruce and Young refer to abstract representations irrespective of viewpoint, as discussed later in this section. When we view a familiar faces we emphasise the consistent aspects of the face and an independent viewpoint is built up over time. Marr ( 1982 ) described this as object-centred  when referring to familiar objects. In the original Bruce and Young model, other types of sensory information influence face recognition, such 72  Disorders of Perception as the sound of the person’s voice or their lip movements, for example. All this physical information is built up in an incremental way until the physical features of the face reaches a point where the conceptual information that identifies the person is triggered in memory at the person identity nodes. While the person’s identity node provides undeniable conceptual information about the person, this model also allows the face recognition unit to provide a visually derived semantic code that may be obtained even for unfamiliar faces: their age and their sex, their look that might reveal a category of personality, e.g. inscrutable. These are conceptual aspects that are tied to the visual form of the face and its expression. The identity code may resolve the feeling of knowing through the activation of the appropriate memory store at the hypothetical person identity node. The model allows that any of the units and nodes may contribute towards the face recognition. It should be noted that in this model it is possible to derive someone’s name or recognise their face following their identification of what they do and where they come from (the arrows in the model go both ways). An example of this situation might arise when a person sees an actor in a film, who is only recognised when the viewer has been told the other films the actor has been in. There are patients who are able to recognise the name, voice or the face but still have no ability to retrieve any biographical information. Therefore, a special box for the person identity node is required for the retrieval of biographical or meaningful information about the person’s identity (e.g. Kapur et al., 1995 ; Gainotti et al., 2009 ; Kartsounis and Shallice, 1996 ). The model may be incomplete, given that emotional information might prompt recognition; also, the serial placement of the boxes in the model might be questioned by the finding that, when presented with a face, recall of information about the person is a better cue for the name, followed by the name of the person’s city, and this unequal access is also shown by the finding that facial information is more easily recalled than their city, which in turn is easier to recall than their name (Moran et al., 2005 ). Study Questions • The most common complaint  for healthy and brain-damaged persons is that they can recognise the face but forget the name. What are some possible reasons for this? • The more information you know about a person, the more likely it is that you will remember their name. Explain why this might be the case in terms of Bruce and Young’s model. How would you change the model to make this prediction more likely? 2.7.2  Neurophysiological Evidence for Face Recognition from Animal and Human Research There are now a number of monkey and human studies that have found specialised face recognition cells within the temporal cortex. These face cells have been investigated by measuring firing rates of individual brain cells when the animal is presented with faces versus control non-facial stimuli or objects. A more global perspective has been achieved by fMRI on monkeys (e.g. Lafer-Sousa and Conway, 2013 ). It appears that while cells within the inferior  temporal cortex are more important for recognising the identity of a face (a picture of a specific monkey’s face), there are cells within the superior  temporal cortex (specifically within the superior temporal sulcus) that fire more selectively to certain expressions, movement and orientation (see Figure  2.27 ). These areas have close connections to areas that process emotions (Rolls, 2008 ). These findings have been replicated in imaging studies with human subjects (e.g. Puce et al., 2000 ; Puce and Perrett, 2003 ). There are also a smaller number of cells that seem to respond only to a combination of identity and facial expression. The superior temporal sulcus appears to be an area that is important for a number of areas of face and social recognition. As described above, fMRI studies of humans implicate the posterior superior temporal sulcus for observing movements (Grosbras et al., 2012 ) and non-human animal experiments show that cells in this area are responsive to hand and body and lip movements (Puce and Perrett, 2003 ). By attaching lights to critical joint areas of the body it is possible to assess the movements of bodies without actually seeing the body. These cues can be useful in person recognition, with the movements of females being distinguished from male’s body movements, for example. Just like faces, these images are more difficult to recognise when they are inverted, suggesting that there is a template based on past experience. These quite different indicators of personal recognition are all found to be associated with activation in the superior temporal sulcus (STS) or superior temporal gyrus (see Figure 2.27 ). In terms of movement perception, there is more right STS activation than left. This has now been demonstrated using fMRI with virtual reality processing of gesture (Morris et al., 2005 ) and animated f igures (Lichtensteiger, 2008 ). These and other findings accentuate the importance of this area in the interpretation of non-verbal social communication. There has already been mention of viewer-centred  (same face viewed at a certain angle to the viewer) and object-centred  (the object is recognised irrespective of its orientation) description. Perrett and colleagues (Perrett et al., 1991 ; Oram and Perrett, 1996 ) report Disorders of Perception  73 the existence of some cells that appear to be dependent on the viewpoint of the observer and some that are not. The majority of cells that have been detected respond to a single orientation of a face. For example these ‘viewer-centred’ cells may respond maximally to a face at 45 per cent orientation in relation to the viewer. However, there are a few cells in this superior temporal area of the macaque monkey that respond irrespective of the face orientation. These 2–5 per cent clever cells pick up a face in all the orientations and are referred to as ‘object-centred cells’. It might be that these object-centred cells might have input from cells that are more restricted in the reception of specific orientations (Ullman, 1998 ). This hierarchically organised system is present for other aspects of vision. The same distribution of cells firing more at a certain orientation has been found with stimuli other Figure 2.27  An illustration of different imaging studies that have found areas of activation within the superior temporal sulcus and gyri that correspond to the perception gaze and head orientation, lip, body and hand movements. For a review of this research see Puce and Perrett ( 2003 ). Figure adapted from Puce and Perrett ( 2003 ), with permission of the Royal Society. than faces. However, many questions remain to be answered. For example, it is assumed that cells exist for some of the orientations but not for all orientations. It is assumed that if there were cells to cope with viewer-centred orientation after the face or object has turned through 40 degrees and 50 degrees then there is some mechanism that predicts the features of the object at 45 degrees. This interpolation would be necessary in order to allow the apparently visually smooth turning of the face or object. Logothetis and Pauls ( 1995 ) conducted an experiment to answer this question. Using novel three-dimensional objects which were especially created for the experiment, they trained primates in this experiment to recognise these originally unfamiliar objects at certain orientations. Cells were then found in the temporal cortex that, after training, showed a significant response to the trained orientations. Despite
The last 20 years has seen the birth and rise of the Web at an astronomical pace. We have witnessed the birth of the Information Age, equal in magnitude to the transition to the modern world from the Middle Ages. We do everything differently. Just as Gutenberg's printing press allowed the accumulated knowledge of the human race to reach every person who could read, the Web extends this knowledge to everyone with access to a computer.
This book is meant to be an accessible introduction to the history of the Web, but we would not have the Web if it were not for the internet. In fact, we don't get to the invention of the World Wide Web until idea 21, the preceding ideas lay its foundations. So this is not only a book of ideas that changed the Web, it also includes those that led to its creation.
While there is a lot of cross-referencing in the book, each essay stands alone. Much as Tim Berners-Lee envisaged the Web, the reader can dip in and out of the book at will, following the links between ideas or reading chronologically from beginning to end. The choice is yours.
Our story starts and ends with a dream. In 1934, a Belgian bibliophile dreamt of a telescope that could transmit electronic documents. In 1999, Tim Berners-Lee outlined his vision for a Semantic Web. An information space of an unimaginable amount of data, automatically interrogated, processed and turned into knowledge. A dream that is now within our grasp.
In between, we have 98 other ideas. Some are revolutionary, like the peer-to-peer network. Others are humble, like the GIF. All of them have contributed to the world-changing phenomenon that is the World Wide Web.
Ideas 1–20 examine the precursors, those ideas that led to the creation of the Web. Without hypertext, the modem, the Graphical User Interface, the mouse, the PC and of course the internet, there would be no Web. The Web and the internet are terms that are often erroneously interchanged, before we get any further, perhaps now is a good time to clarify the difference. The internet is a global system of interconnected computer networks. It is the infrastructure that carries email, instant messaging, Voice over IP, network games, file transfer and the Web. The Web is the most accessible component of the internet, an interlinked system of hypertext documents.
Ideas 21–53 deal with the Web's infancy, introducing the browser, the JPEG, search, multi-player gaming, the webcam, the banner ad, net art, webmail and the blog. These early years were a time of experimentation, a DIY landscape typified by the now-deleted GeoCities. It was a rich period of creative expression dominated by nonconformists. Hackers, artists, and other misfits dived into the unknown and changed the world. Tragically, evidence of this culturally significant period is largely lost. The story of the first webpage, published in August 1991, is typical. It was continually overwritten until March 1992. No copy of the original webpage, not even a screenshot, exists.
Ideas 54–71 address the pre-social Web and the birth of ecommerce. At the end of the last century, dot-com hysteria was in full force. Broadband arrived and the Web began to lose its original spirit. Brands entered cyberspace, as it was then known. Websites became more polished, recognizing the commercial demands of their paymasters. The pivotal moment was the appearance of digital wallets, primarily PayPal. There was a reaction: John Perry Barlow, member of The Grateful Dead, declared ‘the Independence of Cyberspace’ and Shawn Fanning created the first peer-to-peer network. He called it Napster. Then came the crash: those companies that survived not only had deep pockets, they had user-generated content at their heart. Amazon had customer reviews, eBay had user-driven auctions, Wikipedia was entirely written and edited by its users. Even Google had user-generated links.
With ideas 74–98, the Web came of age, becoming dynamic, social and, crucially, mobile. In the early years of the Web, pages were built entirely in HTML. With each click, a new page was loaded. Even a small change to the page meant the entire page had to be refreshed. In 2005, Google launched Google Maps, which behaved more like a software application than a website. Web 2.0 had arrived and with it came the social Web. Although sites like Blogger and Friendster had started long beforehand, it was in 2006 that the social Web really took off. That year, Facebook opened up to everyone of 13 and older, Twitter was founded, YouTube went mainstream, and aggregators like Fark suddenly had the power to take servers down. The launch of the iPhone in 2007 took the Web mobile, at least in Europe and the US, by this point the number of people in Asia accessing the Web via mobile phone exceeded the number browsing on a PC. Our most important device became the one in our pocket. It's the one screen that cuts across our work and leisure time. It's the first screen we look at in the morning and the last one we look at at night.
With ideas 99 and 100 we look to the future. When the Web was first conceived, it was intended to be more than an interconnected library of information. The ultimate aim was a system that drew meaning from this information. In an increasingly connected world, our ability to capture and store data is staggering. When this data is marked up with contextual information, it becomes knowledge and we are one step closer to a Web that thinks. The Semantic Web.
With only 100 ideas, there is not room for every innovation that shaped the Web. The Mother of all Demos, Social Bookmarks, Bitcoin, Twitch TV and the Hash Tag were incorporated within other ideas, others were dismissed entirely. Sorry Shockwave, we had some good times together but it was never going to last. As for the Active Desktop, you were interesting but in the end, just too demanding. The less said about Chat Roulette the better. It was for research purposes, honestly.
While writing this book, it became apparent that exploring the history of the Web is not just a nostalgic trip into our recent digital past but an exploration of the very way we think and communicate. Our thought processes are non-linear and erratic but the way we make sense of things and express ourselves is linear. Pioneers like Paul Otlet, Vannevar Bush, Theodor Nelson, Douglas Engelbart and Tim Berners-Lee questioned this conviction. Their legacy is the World Wide Web. A place that breaks down national and cultural borders. A place that blurs the boundaries between generating and exchanging ideas. A place that has toppled regimes and created new economic models. A place that has radically changed the way we work, play, shop, socialize and otherwise participate in society. But above all, a place that is for everyone.

Have you ever played an April Fool's joke? That's a meme. Have you ever worn your baseball cap back to front? That's a meme too. Have you ever said, ‘Cheers’? You get the idea.
A meme is a behaviour that is transmitted from person to person. The term was coined by evolutionary biologist Richard Dawkins in his 1976 book The Selfish Gene, from the Greek, mimema, meaning ‘imitate’. Examples of memes cited in the book include stories, sayings, fashions and learnt skills. Dawkins sums up a meme as ‘a unit of cultural transmission’, meaning just about anything you can think of is potentially a meme. It can be a phrase, image, behaviour, sound or fashion.
According to Dawkins’ theory, memes evolve in the same way as living things. Some become extinct, some spread and others mutate. The meme is perhaps most simply described by Malcolm Gladwell as ‘an idea that behaves like a virus that moves through a population, taking hold in each person it infects’. This is true, but it confuses a meme with viral content.
Memes differ from viral campaigns in that they evolve and change over time. Crasher Squirrel is a meme, appearing in a different photograph each time it's shared. Dancing Baby is viral; the same file is shared every time.
Historically, a meme would travel via word of mouth, usually as an interesting story, a funny joke or an expression of speech. An internet meme spreads from person to person via social networks, blogs, content aggregators, instant messages and email. Away from the keyboard, memes evolve and spread relatively slowly. On the Web, they can spread extremely rapidly, potentially reaching a global audience in hours.
Internet memes are often humorous, such as Crasher Squirrel or the Star Wars Kid. Humour reaches the most people because it is easy to forward funny content to large numbers of people. Conversational expressions are popular too, such as ‘Keep Calm and …’. Whatever the motive, in each case a piece of customized content spreads between people in a virus-like fashion.
Internet memes have attracted a lot of academic attention. Making ideas stick has enormous potential for influencing social change. Why are some ideas replicated and virally shared, while others are discarded? There appears to be no formula. Although starting with an unamused cat will give you a fighting chance

Every minute, 2 million searches are made, half a billion links are shared and 48 hours of footage are uploaded. That is a lot of data. And yet, in terms of how much is being produced worldwide, it barely scratches the surface. That is Big Data.
Big Data is the term used to describe data sets that are so large and complex that it takes a phenomenal amount of processing power to interrogate them. So why do it?
Fourteen seconds before the 2011 earthquake in Japan, every bullet train and every factory came to a halt. Many lives were saved thanks to the Quake-Catcher Network. This network is made up of thousands of laptops with free software running in the background. The software makes use of the built-in sensors designed to protect the hard drive if the laptop is dropped. If there is an earthquake, all the sensors go off at the same time. By continuously aggregating and processing the data produced by all the sensors, it is possible to brace for impact before the earthquake strikes. Fourteen seconds before, as it turns out.
In an increasingly connected world, our ability to capture and store data is staggering. We have sensors in everything, from running shoes to mobile phones. We are divulging more and more personal information to social networks. We supply more and more customer data to retailers, on-and offline. Around 90 per cent of the data in the world today has been created in the last two years alone. Thanks to the Web, we have gone from information scarcity to information overload in two decades.
Big Data needs big computers to process it. The algorithms that crunch Big Data require thousands of servers running in parallel. Currently, only governments and web giants like Google and Amazon have the necessary resources. Barack Obama got elected off the back of it. Twice. By unifying vast commercial, political and social databases, his team was able to understand and influence individual swing voters (see The Internet Election). Google uses it to predict flu outbreaks, identify human trafficking hot spots and sell advertising.
When the Web was first conceived, it was intended to be more than an interconnected repository of information. The ultimate aim was the Semantic Web, a Web that drew meaning from information. Big Data is half the equation

The inventor of the department store, John Wanamaker, was the first person to buy advertising space in newspapers. He famously said, ‘Half the money I spend on advertising is wasted, the trouble is, I don't know which half.’
That was before the Web was invented, the most measurable medium the world has ever known. The collection and reporting of website visitor data is called web analytics. The earliest online measurement tools, common across GeoCities in the mid-90s, were milometer-style hit counters. These days, web analytics is an industry in its own right.
At a basic level, you can measure the number of people who visit your site, and what the most popular pages are. Dig a little deeper and you can discover entrance and exit pages, the number of repeat visitors and the number of pages viewed per visit. ‘Bounce rate’ is a favoured measure. It reveals how many people came to your site and disappeared without getting beyond the homepage. If it is high, you are either attracting the wrong visitors or not providing the right content. Either way, your website is not working!
For those who do not like numbers, heat maps illustrate at a glance where people are clicking. Visualizations show that users often read webpages in an F-shaped pattern: they scan the top of the page, then make a horizontal sweep across the middle before skimming down the left-hand margin. Collecting this information allows you to make informed decisions about where to place the most important content on a page.
In addition to the huge amount of data that can be collected about visitor behaviour on your website, further analysis can also identify what happens off your website. Links from other sites, search engines, emails, banner ads and social networks can all be tracked.
Links from other sites tell you who your friends are and where else your audience hangs out. By looking at search logs you can see the keywords that led people to your site. This helps guide the type of content you provide and the language you should use. Stats from email and banner campaigns reveal how successful your marketing efforts are. Social media has been called ‘the largest and most honest unselfconscious focus group in the world’ – just be careful what you look for.
We have more data than ever before. The trick is not to measure everything you can, but to collect the data that will lead to meaningful insights. As with a Formula 1 car, lots of small tweaks can make a huge difference to the performance of the overall machine
    </textarea>
</div>
  </div>

  <textarea id="newnet" style="width:100%; display: none" >
  // model parameters
  generator = 'lstm'; // can be 'rnn' or 'lstm'
  hidden_sizes = [20,20]; // list of sizes of hidden layers
  letter_size = 5; // size of letter embeddings

  // optimization
  regc = 0.000001; // L2 regularization strength
  learning_rate = 0.005; // learning rate
  clipval = 5.0; // clip gradients at this value
  </textarea>

  <div id="status" >

<div class="hh"> Settings </div>
      <div class="aslider">
        <div class="slider_header" style="text-align: center;"> Learning Rate:
          <button id="aboutLearningRate" class="aboutButton"> ? </button>
        </div>

        <div class="theslider" id="lr_slider"></div>



      <div style="clear: both;"></div>
    </div>

    <div id="controls">
      <div class="aslider">
        <div class="slider_header" style="text-align: center"> Logic:
        <button id="aboutLogic" class=" aboutButton"> ? </button>
        </div>
        <div class="theslider" id="temperature_slider"></div>
        <div class="slider_value" id="temperature_text"></div>
      </div>
    </div>





  </div>
  <div id="io">
    <div class="hh">Save or Load previous models </div>

    <button id="savemodel" class="abutton">save model</button>
    <button id="loadmodel" class="abutton">load model</button>
    <button id="loadpretrained" class="abutton">load pretrained</button>

    <textarea style="width:100%; height:200px; resize: none;" id="tio"></textarea>
    <br>

    <iframe width="100%" height="166" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/280395518%3Fsecret_token%3Ds-ybPc7&amp;color=ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false"></iframe>
  </div>
</div>

</body>
</html>
